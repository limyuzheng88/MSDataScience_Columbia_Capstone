{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = pd.read_csv('aggregated_table_2024_12_01_6pm.csv')\n",
    "agg = agg[agg['Model'] != 'GPT4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_trad = pd.read_csv('traiditional_ML_results_combined.csv')\n",
    "# agg_trad = agg_trad[agg_trad['Model'] == 'LogisticRegression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Num Features</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Class 1 Proportion</th>\n",
       "      <th>Set ID</th>\n",
       "      <th>Run Number</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>13B-8bit</td>\n",
       "      <td>t_annony</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Set_1_Prop_0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.133956</td>\n",
       "      <td>0.515915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>13B-8bit</td>\n",
       "      <td>t_annony</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Set_2_Prop_0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.123873</td>\n",
       "      <td>0.465959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>13B-8bit</td>\n",
       "      <td>t_annony</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Set_3_Prop_0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.464191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>13B-8bit</td>\n",
       "      <td>t_annony</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Set_4_Prop_0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>0.120330</td>\n",
       "      <td>0.451370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>13B-8bit</td>\n",
       "      <td>t_annony</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Set_5_Prop_0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.125165</td>\n",
       "      <td>0.475685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Prompt Type  Num Features  Sample Size  Class 1 Proportion  \\\n",
       "3771  13B-8bit    t_annony          20.0         32.0                 0.5   \n",
       "3772  13B-8bit    t_annony          20.0         32.0                 0.5   \n",
       "3773  13B-8bit    t_annony          20.0         32.0                 0.5   \n",
       "3774  13B-8bit    t_annony          20.0         32.0                 0.5   \n",
       "3775  13B-8bit    t_annony          20.0         32.0                 0.5   \n",
       "\n",
       "              Set ID  Run Number Accuracy  Precision    Recall  F1 Score  \\\n",
       "3771  Set_1_Prop_0.5         1.0     0.67   0.142857  0.307692  0.195122   \n",
       "3772  Set_2_Prop_0.5         1.0     0.64   0.103448  0.230769  0.142857   \n",
       "3773  Set_3_Prop_0.5         1.0     0.58   0.108108  0.307692  0.160000   \n",
       "3774  Set_4_Prop_0.5         1.0     0.33   0.114286  0.615385  0.192771   \n",
       "3775  Set_5_Prop_0.5         1.0      0.6   0.114286  0.307692  0.166667   \n",
       "\n",
       "                                             Prediction    PR_AUC   ROC_AUC  \n",
       "3771  [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...  0.133956  0.515915  \n",
       "3772  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...  0.123873  0.465959  \n",
       "3773  [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, ...  0.123264  0.464191  \n",
       "3774  [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...  0.120330  0.451370  \n",
       "3775  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...  0.125165  0.475685  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Tuning</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Minority Proportion</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROCAUC</th>\n",
       "      <th>PRAUC</th>\n",
       "      <th>Iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.084405</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.137094</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.083794</td>\n",
       "      <td>0.513263</td>\n",
       "      <td>0.139826</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.185305</td>\n",
       "      <td>0.481432</td>\n",
       "      <td>0.131115</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>No</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.054040</td>\n",
       "      <td>0.480592</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>No</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.144016</td>\n",
       "      <td>0.509947</td>\n",
       "      <td>0.137749</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Tuning  Train Size  Minority Proportion        F1    ROCAUC  \\\n",
       "0  DecisionTree     No           8                  0.1  0.084405  0.505747   \n",
       "1  DecisionTree     No           8                  0.3  0.083794  0.513263   \n",
       "2  DecisionTree     No           8                  0.5  0.185305  0.481432   \n",
       "3  DecisionTree     No          16                  0.1  0.054040  0.480592   \n",
       "4  DecisionTree     No          16                  0.3  0.144016  0.509947   \n",
       "\n",
       "      PRAUC  Iteration  \n",
       "0  0.137094        5.5  \n",
       "1  0.139826        5.5  \n",
       "2  0.131115        5.5  \n",
       "3  0.136000        5.5  \n",
       "4  0.137749        5.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_trad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7B-unquant' '7B-8bit' '13B-8bit']\n"
     ]
    }
   ],
   "source": [
    "# Find unique values\n",
    "unique_values = agg['Model'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Majority Voting Results by Prompt Type:\n",
      "             Ensemble F1\n",
      "Prompt Type             \n",
      "t_annony        0.396087\n",
      "t_table         0.281389\n",
      "\n",
      "Weighted Voting Results by Prompt Type:\n",
      "             Ensemble F1\n",
      "Prompt Type             \n",
      "t_annony        0.149239\n",
      "t_table         0.229471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "def ensemble_predictions(experiment_results_df, voting='majority'):\n",
    "    \"\"\"\n",
    "    Performs ensemble predictions for 3 models and 2 prompt types\n",
    "    \"\"\"\n",
    "    grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Num Features', 'Sample Size', 'Class 1 Proportion'])\n",
    "    ensemble_results = []\n",
    "    \n",
    "    for (prompt_type, num_features, sample_size, class_prop), group in grouped_predictions:\n",
    "        try:\n",
    "            predictions_list = []\n",
    "            for pred in group['Prediction'].tolist():\n",
    "                try:\n",
    "                    if isinstance(pred, str):\n",
    "                        pred_list = ast.literal_eval(pred)\n",
    "                        predictions_list.append(pred_list)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if len(predictions_list) < 2: \n",
    "                continue\n",
    "                \n",
    "            min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "            predictions_list = [pred_list[:min_length] for pred_list in predictions_list]\n",
    "            \n",
    "            ensemble_preds = []\n",
    "            for i in range(min_length):\n",
    "                instance_predictions = []\n",
    "                for pred_list in predictions_list:\n",
    "                    try:\n",
    "                        if isinstance(pred_list[i], (int, float)):\n",
    "                            instance_predictions.append(pred_list[i])\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if instance_predictions:\n",
    "                    if voting == 'majority':\n",
    "                        ensemble_pred = round(sum(instance_predictions) / len(instance_predictions))\n",
    "                    elif voting == 'weighted':\n",
    "                        weights = group['F1 Score'].tolist()\n",
    "                        weighted_sum = sum(p * w for p, w in zip(instance_predictions, weights[:len(instance_predictions)]))\n",
    "                        ensemble_pred = round(weighted_sum / sum(weights[:len(instance_predictions)]))\n",
    "                    ensemble_preds.append(ensemble_pred)\n",
    "            \n",
    "            true_labels = [y for y in predictions_list[0] if isinstance(y, (int, float))][:len(ensemble_preds)]\n",
    "            \n",
    "            if len(true_labels) == len(ensemble_preds) and len(ensemble_preds) > 0:\n",
    "                metrics = {\n",
    "                    'Prompt Type': prompt_type,\n",
    "                    'Num Features': num_features,\n",
    "                    'Sample Size': sample_size,\n",
    "                    'Class 1 Proportion': class_prop,\n",
    "                    'Ensemble F1': f1_score(true_labels, ensemble_preds, zero_division=1)\n",
    "                }\n",
    "                ensemble_results.append(metrics)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(ensemble_results)\n",
    "\n",
    "def run_ensemble_analysis(experiment_results_df):\n",
    "    \"\"\"\n",
    "    Run ensemble analysis for different voting methods\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    majority_results = ensemble_predictions(experiment_results_df, voting='majority')\n",
    "    weighted_results = ensemble_predictions(experiment_results_df, voting='weighted')\n",
    "    \n",
    "    if not majority_results.empty:\n",
    "        majority_results.to_csv('majority_voting_results.csv', index=False)\n",
    "        results['majority'] = majority_results\n",
    "        \n",
    "    if not weighted_results.empty:\n",
    "        weighted_results.to_csv('weighted_voting_results.csv', index=False)\n",
    "        results['weighted'] = weighted_results\n",
    "    \n",
    "    for method, df in results.items():\n",
    "        if not df.empty:\n",
    "            print(f\"\\n{method.capitalize()} Voting Results by Prompt Type:\")\n",
    "            summary = df.groupby('Prompt Type')[['Ensemble F1']].mean()\n",
    "            print(summary)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # experiment_results_df = pd.read_csv('aggregated_table_2024_12_01_6pm.csv')\n",
    "    experiment_results_df = agg\n",
    "    results = run_ensemble_analysis(experiment_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacking Ensemble Results by Prompt Type:\n",
      "             Ensemble F1\n",
      "Prompt Type             \n",
      "t_annony        0.779458\n",
      "t_table         0.800872\n",
      "\n",
      "Confidence Ensemble Results by Prompt Type:\n",
      "             Ensemble F1\n",
      "Prompt Type             \n",
      "t_annony        0.396087\n",
      "t_table         0.281389\n",
      "\n",
      "Dynamic Ensemble Results by Prompt Type:\n",
      "             Ensemble F1\n",
      "Prompt Type             \n",
      "t_annony        0.386992\n",
      "t_table         0.288887\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "# 1. Stacking Ensemble\n",
    "def stacking_ensemble(experiment_results_df, meta_classifier=LogisticRegression()):\n",
    "    \"\"\"\n",
    "    Implements stacking ensemble using a meta-classifier\n",
    "    \"\"\"\n",
    "    grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Num Features', 'Sample Size', 'Class 1 Proportion'])\n",
    "    stacking_results = []\n",
    "    \n",
    "    for (prompt_type, num_features, sample_size, class_prop), group in grouped_predictions:\n",
    "        try:\n",
    "            predictions_list = []\n",
    "            for pred in group['Prediction'].tolist():\n",
    "                try:\n",
    "                    if isinstance(pred, str):\n",
    "                        pred_list = ast.literal_eval(pred)\n",
    "                    else:\n",
    "                        pred_list = pred\n",
    "                    predictions_list.append(pred_list)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if len(predictions_list) < 2: \n",
    "                continue\n",
    "                \n",
    "            min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "            cleaned_predictions = []\n",
    "            for pred_list in predictions_list:\n",
    "                numeric_preds = []\n",
    "                for p in pred_list[:min_length]:\n",
    "                    if isinstance(p, (int, float)):\n",
    "                        numeric_preds.append(float(p))\n",
    "                    else:\n",
    "                        numeric_preds.append(0.0)\n",
    "                cleaned_predictions.append(numeric_preds)\n",
    "            \n",
    "            X_meta = np.array(cleaned_predictions).T\n",
    "            y_true = np.array([float(y) for y in cleaned_predictions[0]])\n",
    "            \n",
    "            if X_meta.shape[0] == len(y_true) and X_meta.shape[0] > 0:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_meta, y_true, test_size=0.2, random_state=42)\n",
    "                meta_classifier.fit(X_train, y_train)\n",
    "                ensemble_preds = meta_classifier.predict(X_test)\n",
    "                \n",
    "                metrics = {\n",
    "                    'Prompt Type': prompt_type,\n",
    "                    'Num Features': num_features,\n",
    "                    'Sample Size': sample_size,\n",
    "                    'Class 1 Proportion': class_prop,\n",
    "                    'Ensemble F1': f1_score(y_test, ensemble_preds, zero_division=1)\n",
    "                }\n",
    "                stacking_results.append(metrics)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(stacking_results)\n",
    "\n",
    "# 2. Confidence-based Voting\n",
    "def confidence_voting(experiment_results_df, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Implements confidence-based voting using model performance metrics\n",
    "    \"\"\"\n",
    "    grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Num Features', 'Sample Size', 'Class 1 Proportion'])\n",
    "    confidence_results = []\n",
    "    \n",
    "    for (prompt_type, num_features, sample_size, class_prop), group in grouped_predictions:\n",
    "        try:\n",
    "            predictions_list = []\n",
    "            for pred in group['Prediction'].tolist():\n",
    "                try:\n",
    "                    if isinstance(pred, str):\n",
    "                        pred_list = ast.literal_eval(pred)\n",
    "                    else:\n",
    "                        pred_list = pred\n",
    "                    predictions_list.append(pred_list)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if len(predictions_list) < 2:\n",
    "                continue\n",
    "                \n",
    "            min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "            predictions_list = [pred_list[:min_length] for pred_list in predictions_list]\n",
    "            confidences = group['F1 Score'].values\n",
    "            \n",
    "            ensemble_preds = []\n",
    "            for i in range(min_length):\n",
    "                instance_predictions = []\n",
    "                instance_confidences = []\n",
    "                \n",
    "                for pred_list, conf in zip(predictions_list, confidences):\n",
    "                    try:\n",
    "                        if isinstance(pred_list[i], (int, float)) and conf >= confidence_threshold:\n",
    "                            instance_predictions.append(pred_list[i])\n",
    "                            instance_confidences.append(conf)\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if instance_predictions:\n",
    "                    weighted_pred = sum(p * c for p, c in zip(instance_predictions, instance_confidences))\n",
    "                    weighted_pred /= sum(instance_confidences)\n",
    "                    ensemble_preds.append(round(weighted_pred))\n",
    "                elif predictions_list:\n",
    "                    ensemble_preds.append(round(np.mean([p[i] for p in predictions_list if isinstance(p[i], (int, float))])))\n",
    "            \n",
    "            true_labels = [y for y in predictions_list[0] if isinstance(y, (int, float))][:len(ensemble_preds)]\n",
    "            \n",
    "            if len(true_labels) == len(ensemble_preds) and len(ensemble_preds) > 0:\n",
    "                metrics = {\n",
    "                    'Prompt Type': prompt_type,\n",
    "                    'Num Features': num_features,\n",
    "                    'Sample Size': sample_size,\n",
    "                    'Class 1 Proportion': class_prop,\n",
    "                    'Ensemble F1': f1_score(true_labels, ensemble_preds, zero_division=1)\n",
    "                }\n",
    "                confidence_results.append(metrics)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(confidence_results)\n",
    "\n",
    "# 3. Dynamic Weighted Voting\n",
    "def dynamic_weighted_voting(experiment_results_df, window_size=3):\n",
    "    \"\"\"\n",
    "    Implements dynamic weighted voting with moving window performance\n",
    "    \"\"\"\n",
    "    grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Num Features', 'Sample Size', 'Class 1 Proportion'])\n",
    "    dynamic_results = []\n",
    "    \n",
    "    for (prompt_type, num_features, sample_size, class_prop), group in grouped_predictions:\n",
    "        try:\n",
    "            predictions_list = []\n",
    "            for pred in group['Prediction'].tolist():\n",
    "                try:\n",
    "                    if isinstance(pred, str):\n",
    "                        pred_list = ast.literal_eval(pred)\n",
    "                    else:\n",
    "                        pred_list = pred\n",
    "                    predictions_list.append(pred_list)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if len(predictions_list) < 2:\n",
    "                continue\n",
    "                \n",
    "            min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "            predictions_list = [pred_list[:min_length] for pred_list in predictions_list]\n",
    "            \n",
    "            f1_scores = group['F1 Score'].values\n",
    "            dynamic_weights = pd.Series(f1_scores).rolling(window=window_size, min_periods=1).mean().values\n",
    "            \n",
    "            ensemble_preds = []\n",
    "            for i in range(min_length):\n",
    "                instance_predictions = []\n",
    "                instance_weights = []\n",
    "                \n",
    "                for pred_list, weight in zip(predictions_list, dynamic_weights):\n",
    "                    try:\n",
    "                        if isinstance(pred_list[i], (int, float)):\n",
    "                            instance_predictions.append(pred_list[i])\n",
    "                            instance_weights.append(weight)\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if instance_predictions:\n",
    "                    weighted_pred = sum(p * w for p, w in zip(instance_predictions, instance_weights))\n",
    "                    weighted_pred /= sum(instance_weights) if sum(instance_weights) > 0 else 1\n",
    "                    ensemble_preds.append(round(weighted_pred))\n",
    "                elif predictions_list:\n",
    "                    ensemble_preds.append(round(np.mean([p[i] for p in predictions_list if isinstance(p[i], (int, float))])))\n",
    "            \n",
    "            true_labels = [y for y in predictions_list[0] if isinstance(y, (int, float))][:len(ensemble_preds)]\n",
    "            \n",
    "            if len(true_labels) == len(ensemble_preds) and len(ensemble_preds) > 0:\n",
    "                metrics = {\n",
    "                    'Prompt Type': prompt_type,\n",
    "                    'Num Features': num_features,\n",
    "                    'Sample Size': sample_size,\n",
    "                    'Class 1 Proportion': class_prop,\n",
    "                    'Ensemble F1': f1_score(true_labels, ensemble_preds, zero_division=1)\n",
    "                }\n",
    "                dynamic_results.append(metrics)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(dynamic_results)\n",
    "\n",
    "def run_all_ensemble_methods(experiment_results_df):\n",
    "    \"\"\"\n",
    "    Run all ensemble methods and compare results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    results['stacking'] = stacking_ensemble(experiment_results_df)\n",
    "    results['confidence'] = confidence_voting(experiment_results_df, confidence_threshold=0.7)\n",
    "    results['dynamic'] = dynamic_weighted_voting(experiment_results_df, window_size=3)\n",
    "    \n",
    "    for method, df in results.items():\n",
    "        if not df.empty:\n",
    "            df.to_csv(f'{method}_ensemble_results.csv', index=False)\n",
    "            print(f\"\\n{method.capitalize()} Ensemble Results by Prompt Type:\")\n",
    "            summary = df.groupby('Prompt Type')[['Ensemble F1']].mean()\n",
    "            print(summary)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # experiment_results_df = pd.read_csv('aggregated_table_2024_12_01_6pm.csv')\n",
    "    experiment_results_df = agg\n",
    "    results = run_all_ensemble_methods(experiment_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WITH SAMPLE SIZES\n",
    "\n",
    "# def stacking_ensemble(experiment_results_df, meta_classifier=LogisticRegression()):\n",
    "#     \"\"\"\n",
    "#     Implements stacking ensemble considering sample sizes and prompt types\n",
    "#     \"\"\"\n",
    "#     grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Sample Size'])\n",
    "#     stacking_results = []\n",
    "    \n",
    "#     for (prompt_type, sample_size), group in grouped_predictions:\n",
    "#         try:\n",
    "#             predictions_list = []\n",
    "#             for pred in group['Prediction'].tolist():\n",
    "#                 try:\n",
    "#                     if isinstance(pred, str):\n",
    "#                         pred_list = ast.literal_eval(pred)\n",
    "#                         predictions_list.append(pred_list)\n",
    "#                 except:\n",
    "#                     continue\n",
    "            \n",
    "#             if len(predictions_list) < 2:\n",
    "#                 continue\n",
    "                \n",
    "#             min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "#             cleaned_predictions = []\n",
    "#             for pred_list in predictions_list:\n",
    "#                 numeric_preds = []\n",
    "#                 for p in pred_list[:min_length]:\n",
    "#                     if isinstance(p, (int, float)):\n",
    "#                         numeric_preds.append(float(p))\n",
    "#                     else:\n",
    "#                         numeric_preds.append(0.0)\n",
    "#                 cleaned_predictions.append(numeric_preds)\n",
    "            \n",
    "#             X_meta = np.array(cleaned_predictions).T\n",
    "#             y_true = np.array([float(y) for y in cleaned_predictions[0]])\n",
    "            \n",
    "#             if X_meta.shape[0] == len(y_true) and X_meta.shape[0] > 0:\n",
    "#                 X_train, X_test, y_train, y_test = train_test_split(X_meta, y_true, test_size=0.2, random_state=42)\n",
    "#                 meta_classifier.fit(X_train, y_train)\n",
    "#                 ensemble_preds = meta_classifier.predict(X_test)\n",
    "                \n",
    "#                 metrics = {\n",
    "#                     'Prompt Type': prompt_type,\n",
    "#                     'Sample Size': sample_size,\n",
    "#                     'Ensemble F1': f1_score(y_test, ensemble_preds, zero_division=1)\n",
    "#                 }\n",
    "#                 stacking_results.append(metrics)\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     return pd.DataFrame(stacking_results)\n",
    "\n",
    "# def confidence_voting(experiment_results_df, confidence_threshold=0.7):\n",
    "#     \"\"\"\n",
    "#     Implements confidence-based voting considering sample sizes and prompt types\n",
    "#     \"\"\"\n",
    "#     grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Sample Size'])\n",
    "#     confidence_results = []\n",
    "    \n",
    "#     for (prompt_type, sample_size), group in grouped_predictions:\n",
    "#         try:\n",
    "#             predictions_list = []\n",
    "#             for pred in group['Prediction'].tolist():\n",
    "#                 try:\n",
    "#                     if isinstance(pred, str):\n",
    "#                         pred_list = ast.literal_eval(pred)\n",
    "#                         predictions_list.append(pred_list)\n",
    "#                 except:\n",
    "#                     continue\n",
    "            \n",
    "#             if len(predictions_list) < 2:\n",
    "#                 continue\n",
    "                \n",
    "#             min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "#             predictions_list = [pred_list[:min_length] for pred_list in predictions_list]\n",
    "#             confidences = group['F1 Score'].values\n",
    "            \n",
    "#             ensemble_preds = []\n",
    "#             for i in range(min_length):\n",
    "#                 instance_predictions = []\n",
    "#                 instance_confidences = []\n",
    "                \n",
    "#                 for pred_list, conf in zip(predictions_list, confidences):\n",
    "#                     try:\n",
    "#                         if isinstance(pred_list[i], (int, float)) and conf >= confidence_threshold:\n",
    "#                             instance_predictions.append(pred_list[i])\n",
    "#                             instance_confidences.append(conf)\n",
    "#                     except:\n",
    "#                         continue\n",
    "                \n",
    "#                 if instance_predictions:\n",
    "#                     weighted_pred = sum(p * c for p, c in zip(instance_predictions, instance_confidences))\n",
    "#                     weighted_pred /= sum(instance_confidences)\n",
    "#                     ensemble_preds.append(round(weighted_pred))\n",
    "#                 elif predictions_list:\n",
    "#                     ensemble_preds.append(round(np.mean([p[i] for p in predictions_list if isinstance(p[i], (int, float))])))\n",
    "            \n",
    "#             true_labels = [y for y in predictions_list[0] if isinstance(y, (int, float))][:len(ensemble_preds)]\n",
    "            \n",
    "#             if len(true_labels) == len(ensemble_preds) and len(ensemble_preds) > 0:\n",
    "#                 metrics = {\n",
    "#                     'Prompt Type': prompt_type,\n",
    "#                     'Sample Size': sample_size,\n",
    "#                     'Ensemble F1': f1_score(true_labels, ensemble_preds, zero_division=1)\n",
    "#                 }\n",
    "#                 confidence_results.append(metrics)\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     return pd.DataFrame(confidence_results)\n",
    "\n",
    "# def dynamic_weighted_voting(experiment_results_df, window_size=3):\n",
    "#     \"\"\"\n",
    "#     Implements dynamic weighted voting considering sample sizes and prompt types\n",
    "#     \"\"\"\n",
    "#     grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Sample Size'])\n",
    "#     dynamic_results = []\n",
    "    \n",
    "#     for (prompt_type, sample_size), group in grouped_predictions:\n",
    "#         try:\n",
    "#             predictions_list = []\n",
    "#             for pred in group['Prediction'].tolist():\n",
    "#                 try:\n",
    "#                     if isinstance(pred, str):\n",
    "#                         pred_list = ast.literal_eval(pred)\n",
    "#                         predictions_list.append(pred_list)\n",
    "#                 except:\n",
    "#                     continue\n",
    "            \n",
    "#             if len(predictions_list) < 2:\n",
    "#                 continue\n",
    "                \n",
    "#             min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "#             predictions_list = [pred_list[:min_length] for pred_list in predictions_list]\n",
    "            \n",
    "#             f1_scores = group['F1 Score'].values\n",
    "#             dynamic_weights = pd.Series(f1_scores).rolling(window=window_size, min_periods=1).mean().values\n",
    "            \n",
    "#             ensemble_preds = []\n",
    "#             for i in range(min_length):\n",
    "#                 instance_predictions = []\n",
    "#                 instance_weights = []\n",
    "                \n",
    "#                 for pred_list, weight in zip(predictions_list, dynamic_weights):\n",
    "#                     try:\n",
    "#                         if isinstance(pred_list[i], (int, float)):\n",
    "#                             instance_predictions.append(pred_list[i])\n",
    "#                             instance_weights.append(weight)\n",
    "#                     except:\n",
    "#                         continue\n",
    "                \n",
    "#                 if instance_predictions:\n",
    "#                     weighted_pred = sum(p * w for p, w in zip(instance_predictions, instance_weights))\n",
    "#                     weighted_pred /= sum(instance_weights) if sum(instance_weights) > 0 else 1\n",
    "#                     ensemble_preds.append(round(weighted_pred))\n",
    "#                 elif predictions_list:\n",
    "#                     ensemble_preds.append(round(np.mean([p[i] for p in predictions_list if isinstance(p[i], (int, float))])))\n",
    "            \n",
    "#             true_labels = [y for y in predictions_list[0] if isinstance(y, (int, float))][:len(ensemble_preds)]\n",
    "            \n",
    "#             if len(true_labels) == len(ensemble_preds) and len(ensemble_preds) > 0:\n",
    "#                 metrics = {\n",
    "#                     'Prompt Type': prompt_type,\n",
    "#                     'Sample Size': sample_size,\n",
    "#                     'Ensemble F1': f1_score(true_labels, ensemble_preds, zero_division=1)\n",
    "#                 }\n",
    "#                 dynamic_results.append(metrics)\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     return pd.DataFrame(dynamic_results)\n",
    "\n",
    "# def run_all_ensemble_methods(experiment_results_df):\n",
    "#     \"\"\"\n",
    "#     Run all ensemble methods and compare results by prompt type and sample size\n",
    "#     \"\"\"\n",
    "\n",
    "#     experiment_results_df = experiment_results_df[~experiment_results_df['Model'].str.contains('gpt4', case=False)]\n",
    "\n",
    "#     results = {}\n",
    "    \n",
    "#     results['stacking'] = stacking_ensemble(experiment_results_df)\n",
    "#     results['confidence'] = confidence_voting(experiment_results_df, confidence_threshold=0.7)\n",
    "#     results['dynamic'] = dynamic_weighted_voting(experiment_results_df, window_size=3)\n",
    "    \n",
    "#     for method, df in results.items():\n",
    "#         if not df.empty:\n",
    "#             df.to_csv(f'{method}_ensemble_results.csv', index=False)\n",
    "#             print(f\"\\n{method.capitalize()} Ensemble Results:\")\n",
    "#             summary = df.pivot_table(\n",
    "#                 values='Ensemble F1',\n",
    "#                 index='Prompt Type',\n",
    "#                 columns='Sample Size',\n",
    "#                 aggfunc='mean'\n",
    "#             )\n",
    "#             print(summary)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # experiment_results_df = pd.read_csv('aggregated_table_2024_12_01_6pm.csv')\n",
    "#     experiment_results_df = agg\n",
    "\n",
    "#     results = run_all_ensemble_methods(experiment_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #WITH SAMPLE SIZES\n",
    "\n",
    "# def ensemble_predictions(experiment_results_df, voting='majority'):\n",
    "#     \"\"\"\n",
    "#     Performs ensemble predictions for 3 models and 2 prompt types, considering sample sizes\n",
    "#     \"\"\"\n",
    "#     experiment_results_df = experiment_results_df[~experiment_results_df['Model'].str.contains('gpt4', case=False)]\n",
    "\n",
    "#     grouped_predictions = experiment_results_df.groupby(['Prompt Type', 'Sample Size'])\n",
    "#     ensemble_results = []\n",
    "    \n",
    "#     for (prompt_type, sample_size), group in grouped_predictions:\n",
    "#         try:\n",
    "#             predictions_list = []\n",
    "#             for pred in group['Prediction'].tolist():\n",
    "#                 try:\n",
    "#                     if isinstance(pred, str):\n",
    "#                         pred_list = ast.literal_eval(pred)\n",
    "#                         predictions_list.append(pred_list)\n",
    "#                 except:\n",
    "#                     continue\n",
    "            \n",
    "#             if len(predictions_list) < 2:\n",
    "#                 continue\n",
    "                \n",
    "#             min_length = min(len(pred_list) for pred_list in predictions_list)\n",
    "#             predictions_list = [pred_list[:min_length] for pred_list in predictions_list]\n",
    "            \n",
    "#             ensemble_preds = []\n",
    "#             for i in range(min_length):\n",
    "#                 instance_predictions = []\n",
    "#                 for pred_list in predictions_list:\n",
    "#                     try:\n",
    "#                         if isinstance(pred_list[i], (int, float)):\n",
    "#                             instance_predictions.append(pred_list[i])\n",
    "#                     except:\n",
    "#                         continue\n",
    "                \n",
    "#                 if instance_predictions:\n",
    "#                     if voting == 'majority':\n",
    "#                         ensemble_pred = round(sum(instance_predictions) / len(instance_predictions))\n",
    "#                     elif voting == 'weighted':\n",
    "#                         weights = group['F1 Score'].tolist()\n",
    "#                         weighted_sum = sum(p * w for p, w in zip(instance_predictions, weights[:len(instance_predictions)]))\n",
    "#                         ensemble_pred = round(weighted_sum / sum(weights[:len(instance_predictions)]))\n",
    "#                     ensemble_preds.append(ensemble_pred)\n",
    "            \n",
    "#             true_labels = [y for y in predictions_list[0] if isinstance(y, (int, float))][:len(ensemble_preds)]\n",
    "            \n",
    "#             if len(true_labels) == len(ensemble_preds) and len(ensemble_preds) > 0:\n",
    "#                 metrics = {\n",
    "#                     'Prompt Type': prompt_type,\n",
    "#                     'Sample Size': sample_size,\n",
    "#                     'Ensemble F1': f1_score(true_labels, ensemble_preds, zero_division=1)\n",
    "#                 }\n",
    "#                 ensemble_results.append(metrics)\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     return pd.DataFrame(ensemble_results)\n",
    "\n",
    "# def run_ensemble_analysis(experiment_results_df):\n",
    "#     experiment_results_df = experiment_results_df[~experiment_results_df['Model'].str.contains('gpt4', case=False)]\n",
    "\n",
    "#     \"\"\"\n",
    "#     Run ensemble analysis for different voting methods\n",
    "#     \"\"\"\n",
    "#     results = {}\n",
    "    \n",
    "#     majority_results = ensemble_predictions(experiment_results_df, voting='majority')\n",
    "#     weighted_results = ensemble_predictions(experiment_results_df, voting='weighted')\n",
    "    \n",
    "#     if not majority_results.empty:\n",
    "#         majority_results.to_csv('majority_voting_results.csv', index=False)\n",
    "#         results['majority'] = majority_results\n",
    "        \n",
    "#     if not weighted_results.empty:\n",
    "#         weighted_results.to_csv('weighted_voting_results.csv', index=False)\n",
    "#         results['weighted'] = weighted_results\n",
    "    \n",
    "#     for method, df in results.items():\n",
    "#         if not df.empty:\n",
    "#             print(f\"\\n{method.capitalize()} Voting Results:\")\n",
    "#             summary = df.pivot_table(\n",
    "#                 values='Ensemble F1',\n",
    "#                 index='Prompt Type',\n",
    "#                 columns='Sample Size',\n",
    "#                 aggfunc='mean'\n",
    "#             )\n",
    "#             print(summary)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # experiment_results_df = pd.read_csv('aggregated_table_2024_12_01_6pm.csv')\n",
    "#     experiment_results_df = agg\n",
    "\n",
    "#     results = run_ensemble_analysis(experiment_results_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21cc14e713d34a4da6a3e242d1209991": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25c2243d511b4510900fa6ef490265d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_ac214ba153eb4e58aad39877215ab795",
      "style": "IPY_MODEL_3267b30962ae4a699f781d52efc48a72",
      "value": false
     }
    },
    "267e5a9af6be4189a59d358b1e7201bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7256681c2b724b86bfad2ab41abcc8db",
      "placeholder": "​",
      "style": "IPY_MODEL_3fd45887f8b14fa4867070432c943a6b",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "2c65f06d295247e78482fb94e91d9fee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7f0d1dc1af444c18e277a28f3a5d916",
      "placeholder": "​",
      "style": "IPY_MODEL_d30a570bd7ee45b18e65257bb1735bc8",
      "value": "Connecting..."
     }
    },
    "3267b30962ae4a699f781d52efc48a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fd45887f8b14fa4867070432c943a6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4009cccf39c747449dea4c54a1f3ba26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40cc79790f9647999aef90146083a812": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_d03750a88e8b44948e3b7f6647cde940",
      "style": "IPY_MODEL_b918ec279be048ea942b43a70b36e67f",
      "tooltip": ""
     }
    },
    "42f023638bcd405ab1a0fa0279ee27fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f970a86cc414ec0be938b1918ce20e0",
       "IPY_MODEL_db6785e379cd4a69b5849e295b8dd9e4",
       "IPY_MODEL_4850816b90314a49a7f51d79b6fd980b"
      ],
      "layout": "IPY_MODEL_b471b38108224c6f93815adc09cbed37"
     }
    },
    "480ed05a54a24daf9d1839aea3a434f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4850816b90314a49a7f51d79b6fd980b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbf4b5daf6e3451685638f9a86cd689d",
      "placeholder": "​",
      "style": "IPY_MODEL_55a5df6dcab34f29b953fcff64cda1f1",
      "value": " 6/6 [07:17&lt;00:00, 68.39s/it]"
     }
    },
    "4b512133b24949748aba65d6ed8e43f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55a5df6dcab34f29b953fcff64cda1f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "621a55d0590b48a4a7edfaac4994215c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "724d4be404c94ceeb1a5992be33a6015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21cc14e713d34a4da6a3e242d1209991",
      "placeholder": "​",
      "style": "IPY_MODEL_621a55d0590b48a4a7edfaac4994215c",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "7256681c2b724b86bfad2ab41abcc8db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "744877ddd0d2437d92b94515aeb1ace0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_ea224125d7554acdb5149c6fa848553f"
     }
    },
    "8f970a86cc414ec0be938b1918ce20e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be0c241eb25a41898200d0800000165f",
      "placeholder": "​",
      "style": "IPY_MODEL_f4a5356c3643482381bea83274bbdea1",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "96b99fa776b146c3a33064d1aec2300a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_4b512133b24949748aba65d6ed8e43f4",
      "placeholder": "​",
      "style": "IPY_MODEL_480ed05a54a24daf9d1839aea3a434f6",
      "value": ""
     }
    },
    "ac214ba153eb4e58aad39877215ab795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b471b38108224c6f93815adc09cbed37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b918ec279be048ea942b43a70b36e67f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "be0c241eb25a41898200d0800000165f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03750a88e8b44948e3b7f6647cde940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d30a570bd7ee45b18e65257bb1735bc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db6785e379cd4a69b5849e295b8dd9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e188a0eb74bd41dba481fd0a4b3620d7",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4009cccf39c747449dea4c54a1f3ba26",
      "value": 6
     }
    },
    "e188a0eb74bd41dba481fd0a4b3620d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea224125d7554acdb5149c6fa848553f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "f4a5356c3643482381bea83274bbdea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7f0d1dc1af444c18e277a28f3a5d916": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbf4b5daf6e3451685638f9a86cd689d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
