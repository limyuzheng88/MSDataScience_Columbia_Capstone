{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj8-QaHp7T53",
        "outputId": "2a8a905e-68c9-4295-f85d-a6cc05ce2442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import math"
      ],
      "metadata": {
        "id": "1dGt5W5e74_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp_ohe = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/rf_importances.csv')\n",
        "feature_imp_label = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/rf_importances_label.csv')\n",
        "\n",
        "train_ohe = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/train_tree.csv')\n",
        "train_ohe = train_ohe[~train_ohe[\"Approved_Flag\"].isna()]\n",
        "train_label = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/train_label.csv')\n",
        "train_label = train_label[~train_label[\"Approved_Flag\"].isna()]\n",
        "train_lr = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/train_lr.csv')\n",
        "train_lr = train_lr[~train_lr[\"Approved_Flag\"].isna()]\n",
        "\n",
        "test_ohe = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/test_tree.csv')\n",
        "test_label = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/test_label.csv')\n",
        "test_ohe = test_ohe[~test_ohe[\"Approved_Flag\"].isna()]\n",
        "test_label = test_label[~test_label[\"Approved_Flag\"].isna()]\n",
        "test_lr = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/test_lr.csv')\n",
        "test_lr = test_lr[~test_lr[\"Approved_Flag\"].isna()]\n",
        "\n",
        "test_set_index = pd.read_csv('/content/drive/MyDrive/Indian_bank_data/test_set_index.csv')\n",
        "test_set_index = test_set_index[\"index\"].to_list()\n",
        "\n",
        "test_ohe_100 = test_ohe.loc[test_set_index]\n",
        "test_label_100 = test_label.loc[test_set_index]\n",
        "test_lr_100 = test_lr.loc[test_set_index]"
      ],
      "metadata": {
        "id": "UqrkBXQL7bky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models_with_tuning(\n",
        "    train_ohe,\n",
        "    train_label,\n",
        "    train_lr,\n",
        "    test_ohe_100,\n",
        "    test_label_100,\n",
        "    test_lr_100,\n",
        "    sizes,\n",
        "    random_state=42,\n",
        "    hyperparameter_tuning=False\n",
        "):\n",
        "    results = []\n",
        "\n",
        "    # Define hyperparameter grids\n",
        "    param_grids = {\n",
        "        \"RandomForest\": {\n",
        "            \"n_estimators\": [10, 50, 100, 200],\n",
        "            \"max_depth\": [None, 10, 20, 30],\n",
        "            \"min_samples_split\": [2, 5, 10],\n",
        "            \"min_samples_leaf\": [1, 2, 4],\n",
        "        },\n",
        "        \"DecisionTree\": {\n",
        "            \"max_depth\": [None, 10, 20, 30],\n",
        "            \"min_samples_split\": [2, 5, 10],\n",
        "            \"min_samples_leaf\": [1, 2, 4],\n",
        "        },\n",
        "        \"XGBoost\": {\n",
        "            \"n_estimators\": [50, 100, 200],\n",
        "            \"max_depth\": [3, 5, 10],\n",
        "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "            \"subsample\": [0.6, 0.8, 1.0],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Iterate over training sizes\n",
        "    for size in sizes:\n",
        "        # Sampling training data\n",
        "        stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=len(train_ohe) - size, random_state=random_state)\n",
        "        train_idx, _ = next(stratified_split.split(train_ohe, train_ohe[\"Approved_Flag\"]))\n",
        "\n",
        "        sampled_train_ohe = train_ohe.iloc[train_idx]\n",
        "\n",
        "        stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=len(train_lr) - size, random_state=random_state)\n",
        "        train_idx, _ = next(stratified_split.split(train_lr, train_lr[\"Approved_Flag\"]))\n",
        "        sampled_train_lr = train_lr.iloc[train_idx]\n",
        "        # sampled_indices_ohe = train_ohe.sample(size).index\n",
        "        # sampled_train_ohe = train_ohe.loc[sampled_indices_ohe]\n",
        "        # sampled_indices_lr = train_lr.sample(size).index\n",
        "        # sampled_train_lr = train_lr.loc[sampled_indices_lr]\n",
        "\n",
        "        X_train_tree = sampled_train_ohe.drop(columns=\"Approved_Flag\")\n",
        "        y_train_tree = sampled_train_ohe[\"Approved_Flag\"]\n",
        "        X_train_lr = sampled_train_lr.drop(columns=\"Approved_Flag\")\n",
        "        y_train_lr = sampled_train_lr[\"Approved_Flag\"]\n",
        "\n",
        "        X_test_tree = test_ohe_100.drop(columns=\"Approved_Flag\")\n",
        "        y_test_tree = test_label_100[\"Approved_Flag\"]\n",
        "        X_test_lr = test_lr_100.drop(columns=\"Approved_Flag\")\n",
        "        y_test_lr = test_lr_100[\"Approved_Flag\"]\n",
        "\n",
        "        # Models\n",
        "        models_tree = {\n",
        "            \"RandomForest\": RandomForestClassifier(),\n",
        "            \"DecisionTree\": DecisionTreeClassifier(max_depth=int(math.log2(len(train_idx)))),\n",
        "            \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "        }\n",
        "        model_lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "        # Train and evaluate tree-based models\n",
        "        for model_name, model in models_tree.items():\n",
        "            if hyperparameter_tuning:\n",
        "                # Perform RandomizedSearchCV\n",
        "                search = RandomizedSearchCV(\n",
        "                    estimator=model,\n",
        "                    param_distributions=param_grids[model_name],\n",
        "                    n_iter=10,\n",
        "                    scoring=\"roc_auc\",\n",
        "                    cv=3,\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1\n",
        "                )\n",
        "                search.fit(X_train_tree, y_train_tree)\n",
        "                model = search.best_estimator_\n",
        "            else:\n",
        "                model.fit(X_train_tree, y_train_tree)\n",
        "\n",
        "            preds = model.predict(X_test_tree)\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                probs = model.predict_proba(X_test_tree)\n",
        "                if probs.shape[1] > 1:\n",
        "                    probs = probs[:, 1]  # Take probabilities of the positive class\n",
        "                else:\n",
        "                    probs = probs[:, 0]  # Single column output\n",
        "            else:\n",
        "                # Use predictions as probabilities for models without `predict_proba`\n",
        "                probs = preds\n",
        "            print(model_name)\n",
        "            print(\"preds\")\n",
        "            print(preds)\n",
        "            print(\"probs\")\n",
        "            print(probs)\n",
        "            results.append({\n",
        "                \"Model\": model_name,\n",
        "                \"Train Size\": size,\n",
        "                \"F1\": f1_score(y_test_tree, preds),\n",
        "                \"ROCAUC\": roc_auc_score(y_test_tree, probs),\n",
        "                \"PRAUC\": average_precision_score(y_test_tree, probs)\n",
        "            })\n",
        "\n",
        "        # Train and evaluate logistic regression\n",
        "        model_lr.fit(X_train_lr, y_train_lr)\n",
        "        preds = model_lr.predict(X_test_lr)\n",
        "        probs = model_lr.predict_proba(X_test_lr)[:, 1]  # Logistic regression always outputs two classes\n",
        "        print(\"LR\")\n",
        "        print(\"preds\")\n",
        "        print(preds)\n",
        "        print(\"probs\")\n",
        "        print(probs)\n",
        "        results.append({\n",
        "            \"Model\": \"LogisticRegression\",\n",
        "            \"Train Size\": size,\n",
        "            \"F1\": f1_score(y_test_lr, preds),\n",
        "            \"ROCAUC\": roc_auc_score(y_test_lr, probs),\n",
        "            \"PRAUC\": average_precision_score(y_test_lr, probs)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "g0svBCOA8_mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store results\n",
        "all_results = []\n",
        "train_sizes = [128]\n",
        "# Define number of repetitions\n",
        "n_repeats = 10\n",
        "\n",
        "# Run evaluation 10 times for both without and with hyperparameter tuning\n",
        "for i in range(n_repeats):\n",
        "    # Evaluate without hyperparameter tuning\n",
        "    results_no_tuning = evaluate_models_with_tuning(\n",
        "        train_ohe,\n",
        "        train_label,\n",
        "        train_lr,\n",
        "        test_ohe_100,\n",
        "        test_label_100,\n",
        "        test_lr_100,\n",
        "        train_sizes,\n",
        "        random_state=i,\n",
        "        hyperparameter_tuning=False\n",
        "    )\n",
        "    # Add iteration number and tuning type\n",
        "    results_no_tuning[\"Iteration\"] = i + 1\n",
        "    results_no_tuning[\"Tuning\"] = \"No\"\n",
        "\n",
        "    # Evaluate with hyperparameter tuning\n",
        "    results_with_tuning = evaluate_models_with_tuning(\n",
        "        train_ohe,\n",
        "        train_label,\n",
        "        train_lr,\n",
        "        test_ohe_100,\n",
        "        test_label_100,\n",
        "        test_lr_100,\n",
        "        train_sizes,\n",
        "        random_state=i,\n",
        "        hyperparameter_tuning=True\n",
        "    )\n",
        "    # Add iteration number and tuning type\n",
        "    results_with_tuning[\"Iteration\"] = i + 1\n",
        "    results_with_tuning[\"Tuning\"] = \"Yes\"\n",
        "\n",
        "    # Append both results to the list\n",
        "    all_results.append(results_no_tuning)\n",
        "    all_results.append(results_with_tuning)\n",
        "\n",
        "# Combine all results into a single DataFrame\n",
        "final_results = pd.concat(all_results, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_wdsns2JHcJC",
        "outputId": "40e1e067-1ee0-49e6-f1fc-ceea5766403c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.07 0.15 0.07 0.21 0.09 0.14 0.18 0.1  0.15 0.07 0.12 0.09 0.07 0.07\n",
            " 0.17 0.13 0.1  0.15 0.21 0.21 0.1  0.17 0.12 0.09 0.09 0.12 0.1  0.14\n",
            " 0.12 0.04 0.14 0.18 0.13 0.25 0.1  0.12 0.25 0.2  0.1  0.06 0.15 0.18\n",
            " 0.08 0.07 0.14 0.11 0.14 0.12 0.08 0.15 0.15 0.16 0.18 0.1  0.18 0.1\n",
            " 0.16 0.1  0.13 0.15 0.24 0.16 0.06 0.07 0.06 0.33 0.12 0.09 0.09 0.14\n",
            " 0.2  0.16 0.29 0.11 0.11 0.04 0.14 0.09 0.2  0.14 0.07 0.12 0.12 0.11\n",
            " 0.13 0.13 0.15 0.08 0.07 0.17 0.1  0.12 0.11 0.19 0.08 0.12 0.09 0.22\n",
            " 0.22 0.13]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0.]\n",
            "probs\n",
            "[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:49:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "probs\n",
            "[0.06078685 0.02487194 0.13593777 0.07653569 0.00520674 0.04359728\n",
            " 0.16077524 0.20728843 0.00683431 0.00146924 0.05650834 0.0067746\n",
            " 0.01422152 0.00327899 0.01454899 0.13898137 0.2553521  0.05789257\n",
            " 0.07634473 0.02634259 0.05429378 0.03148732 0.03050511 0.03584094\n",
            " 0.00493483 0.74746805 0.02799622 0.01468639 0.00863943 0.00148907\n",
            " 0.17073953 0.03251158 0.00514818 0.11814272 0.01085432 0.01360912\n",
            " 0.7670711  0.03388792 0.0307399  0.03005156 0.03509373 0.01869144\n",
            " 0.00881608 0.01572339 0.0164246  0.00238059 0.04603942 0.02500979\n",
            " 0.01662603 0.00566351 0.05272297 0.14639817 0.04646521 0.00455176\n",
            " 0.00238495 0.007387   0.14076935 0.00269493 0.4727828  0.01304678\n",
            " 0.01188248 0.05392817 0.08409036 0.00382513 0.00991333 0.18322629\n",
            " 0.00600702 0.0075989  0.0025959  0.0112803  0.11465952 0.05208451\n",
            " 0.09998245 0.29411376 0.00363896 0.00123844 0.01751617 0.01698937\n",
            " 0.02667423 0.02503468 0.07413152 0.0475318  0.00639702 0.00480188\n",
            " 0.0050348  0.00671042 0.02707061 0.005575   0.0013648  0.6470747\n",
            " 0.00457763 0.01885249 0.12469485 0.03696802 0.04605005 0.05012465\n",
            " 0.0075278  0.07039686 0.19202535 0.04865315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[5.54189778e-02 5.12019708e-02 6.38822718e-02 8.00336922e-01\n",
            " 3.57801449e-02 2.10360302e-02 5.25566775e-02 2.82547956e-03\n",
            " 4.95529315e-02 1.11055759e-01 1.00476376e-03 3.54933971e-02\n",
            " 7.36014994e-03 3.82496895e-02 1.70084201e-03 1.03545331e-01\n",
            " 7.03048374e-02 1.62260189e-01 1.04347337e-01 2.02043112e-02\n",
            " 6.37552058e-02 0.00000000e+00 1.40075209e-01 3.60770195e-02\n",
            " 7.61116161e-02 1.08686054e-01 1.83270828e-01 5.51258087e-01\n",
            " 0.00000000e+00 7.31139715e-03 1.16455734e-01 3.42654316e-03\n",
            " 1.38726600e-02 3.00570564e-03 1.95143868e-01 2.35447406e-03\n",
            " 0.00000000e+00 9.82304243e-01 7.42792973e-02 3.47472863e-02\n",
            " 1.68054651e-01 2.07319441e-01 5.27087984e-02 5.14701147e-02\n",
            " 1.05356695e-01 1.05869586e-01 2.55108228e-02 1.92278766e-02\n",
            " 2.57432521e-02 9.55774511e-03 1.60720544e-01 3.22787748e-01\n",
            " 1.29972615e-01 4.34096472e-02 1.21575360e-03 7.95833494e-02\n",
            " 9.89891325e-02 2.30421575e-03 2.43288576e-02 4.73175270e-02\n",
            " 9.88827712e-01 8.19841038e-02 4.93903145e-02 1.25254059e-01\n",
            " 3.45369129e-02 5.14107432e-01 7.30785972e-02 8.80029430e-02\n",
            " 7.52659410e-04 1.99813707e-01 3.42347361e-02 3.68108854e-01\n",
            " 5.02352316e-03 2.45599500e-02 4.09664261e-02 3.39309311e-02\n",
            " 5.98748654e-01 7.71183124e-02 1.70891357e-02 4.46344251e-02\n",
            " 6.51290055e-03 1.68353874e-01 1.11126591e-01 1.72992095e-01\n",
            " 6.68937703e-02 2.17167234e-01 0.00000000e+00 1.13055579e-02\n",
            " 1.20649193e-01 4.39325457e-01 8.16496991e-02 3.83744421e-01\n",
            " 3.74980342e-02 6.32872311e-01 1.21291511e-01 1.47131057e-01\n",
            " 1.62932638e-01 3.60986518e-03 3.00099599e-01 6.98789681e-02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.025      0.14141026 0.16969697 0.09166667 0.10833333 0.09166667\n",
            " 0.075      0.11641026 0.09469697 0.025      0.10833333 0.09353147\n",
            " 0.18444056 0.08141026 0.09166667 0.05833333 0.06666667 0.1582684\n",
            " 0.14141026 0.0952381  0.05833333 0.11333333 0.11833333 0.15110723\n",
            " 0.13141026 0.085      0.03333333 0.22969697 0.17212121 0.08141026\n",
            " 0.14141026 0.09166667 0.08141026 0.19545455 0.11833333 0.08141026\n",
            " 0.30878788 0.25142857 0.1018648  0.09807692 0.24015152 0.09333333\n",
            " 0.05641026 0.06136364 0.18878788 0.16833333 0.19829337 0.10378788\n",
            " 0.12136364 0.10833333 0.09166667 0.09166667 0.15166667 0.10833333\n",
            " 0.13141026 0.08141026 0.05641026 0.075      0.025      0.14141026\n",
            " 0.25878788 0.13141026 0.08444056 0.05833333 0.11136364 0.37545455\n",
            " 0.025      0.08141026 0.04807692 0.05833333 0.08141026 0.11666667\n",
            " 0.24212121 0.21777389 0.08141026 0.08141026 0.13878788 0.05833333\n",
            " 0.19666667 0.05641026 0.025      0.10378788 0.11641026 0.11833333\n",
            " 0.1452381  0.06136364 0.05833333 0.10378788 0.03333333 0.05833333\n",
            " 0.14469697 0.03333333 0.085      0.12666667 0.24444056 0.13045455\n",
            " 0.05833333 0.14166667 0.14015152 0.15681818]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.5        0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.42857143 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.5        0.         0.\n",
            " 0.42857143 0.42857143 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.5        0.         0.         0.         0.\n",
            " 0.5        0.         0.         0.         0.         0.\n",
            " 0.42857143 0.         0.         0.         0.         0.42857143\n",
            " 0.         0.         0.         0.         0.         0.5\n",
            " 0.42857143 0.         0.         0.         0.         0.\n",
            " 0.42857143 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.5        0.         0.        ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:50:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "probs\n",
            "[1.55033199e-02 4.30619046e-02 4.56848405e-02 3.91331650e-02\n",
            " 2.27866173e-02 5.75582087e-02 1.82222411e-01 9.13804293e-01\n",
            " 1.19823059e-02 7.38342002e-04 1.82067323e-02 1.89872403e-02\n",
            " 2.12668460e-02 1.62147265e-03 1.07540220e-01 1.94319133e-02\n",
            " 4.14486289e-01 3.39174159e-02 1.10472627e-01 5.58535978e-02\n",
            " 1.33617464e-02 8.89917463e-03 9.36263707e-03 7.77330026e-02\n",
            " 3.19632888e-03 5.08383393e-01 8.17156583e-03 4.97648632e-03\n",
            " 4.23295610e-03 1.19648105e-03 1.85808495e-01 2.07605064e-02\n",
            " 1.76227314e-03 2.02797383e-01 4.40348163e-02 1.71721131e-02\n",
            " 8.69971693e-01 8.02616179e-02 1.21586464e-01 1.37378350e-02\n",
            " 1.10164374e-01 1.90345868e-02 6.29207818e-03 5.64402482e-03\n",
            " 9.38713457e-03 7.18265306e-03 6.92014620e-02 1.13960057e-01\n",
            " 1.70654450e-02 6.72848755e-03 2.75956243e-02 1.96434870e-01\n",
            " 4.15933356e-02 2.66049011e-03 8.29585653e-04 1.27619868e-02\n",
            " 3.76436085e-01 2.78183213e-03 1.29865915e-01 2.25779880e-03\n",
            " 2.31551751e-02 1.88479021e-01 3.51622738e-02 1.80368999e-03\n",
            " 7.49631319e-03 3.47034901e-01 4.36498225e-03 4.86653065e-03\n",
            " 2.54753442e-03 3.15141235e-03 1.93581525e-02 1.00620007e-02\n",
            " 1.51452079e-01 3.70641574e-02 2.72538047e-03 1.05309358e-03\n",
            " 1.09098684e-02 8.09792709e-03 1.45105952e-02 2.56395787e-02\n",
            " 2.81515718e-02 4.61426936e-02 5.64205321e-03 1.39097776e-03\n",
            " 1.84536772e-03 1.23121412e-02 9.83526465e-03 2.74360995e-03\n",
            " 2.35797744e-03 6.38269961e-01 2.76740221e-03 4.64248881e-02\n",
            " 9.28381458e-02 2.72052102e-02 5.22393994e-02 3.94064486e-02\n",
            " 7.52662122e-03 1.08682744e-01 2.87588716e-01 9.24377292e-02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[5.54189778e-02 5.12019708e-02 6.38822718e-02 8.00336922e-01\n",
            " 3.57801449e-02 2.10360302e-02 5.25566775e-02 2.82547956e-03\n",
            " 4.95529315e-02 1.11055759e-01 1.00476376e-03 3.54933971e-02\n",
            " 7.36014994e-03 3.82496895e-02 1.70084201e-03 1.03545331e-01\n",
            " 7.03048374e-02 1.62260189e-01 1.04347337e-01 2.02043112e-02\n",
            " 6.37552058e-02 0.00000000e+00 1.40075209e-01 3.60770195e-02\n",
            " 7.61116161e-02 1.08686054e-01 1.83270828e-01 5.51258087e-01\n",
            " 0.00000000e+00 7.31139715e-03 1.16455734e-01 3.42654316e-03\n",
            " 1.38726600e-02 3.00570564e-03 1.95143868e-01 2.35447406e-03\n",
            " 0.00000000e+00 9.82304243e-01 7.42792973e-02 3.47472863e-02\n",
            " 1.68054651e-01 2.07319441e-01 5.27087984e-02 5.14701147e-02\n",
            " 1.05356695e-01 1.05869586e-01 2.55108228e-02 1.92278766e-02\n",
            " 2.57432521e-02 9.55774511e-03 1.60720544e-01 3.22787748e-01\n",
            " 1.29972615e-01 4.34096472e-02 1.21575360e-03 7.95833494e-02\n",
            " 9.89891325e-02 2.30421575e-03 2.43288576e-02 4.73175270e-02\n",
            " 9.88827712e-01 8.19841038e-02 4.93903145e-02 1.25254059e-01\n",
            " 3.45369129e-02 5.14107432e-01 7.30785972e-02 8.80029430e-02\n",
            " 7.52659410e-04 1.99813707e-01 3.42347361e-02 3.68108854e-01\n",
            " 5.02352316e-03 2.45599500e-02 4.09664261e-02 3.39309311e-02\n",
            " 5.98748654e-01 7.71183124e-02 1.70891357e-02 4.46344251e-02\n",
            " 6.51290055e-03 1.68353874e-01 1.11126591e-01 1.72992095e-01\n",
            " 6.68937703e-02 2.17167234e-01 0.00000000e+00 1.13055579e-02\n",
            " 1.20649193e-01 4.39325457e-01 8.16496991e-02 3.83744421e-01\n",
            " 3.74980342e-02 6.32872311e-01 1.21291511e-01 1.47131057e-01\n",
            " 1.62932638e-01 3.60986518e-03 3.00099599e-01 6.98789681e-02]\n",
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.18 0.08 0.13 0.26 0.12 0.06 0.2  0.13 0.21 0.21 0.19 0.19 0.2  0.09\n",
            " 0.15 0.09 0.07 0.17 0.09 0.08 0.16 0.11 0.25 0.28 0.2  0.18 0.24 0.16\n",
            " 0.16 0.14 0.16 0.24 0.03 0.27 0.1  0.13 0.17 0.15 0.16 0.14 0.34 0.11\n",
            " 0.21 0.21 0.23 0.09 0.18 0.21 0.18 0.2  0.27 0.12 0.2  0.14 0.09 0.07\n",
            " 0.22 0.36 0.08 0.13 0.15 0.19 0.06 0.14 0.35 0.21 0.11 0.27 0.1  0.08\n",
            " 0.3  0.23 0.17 0.17 0.17 0.1  0.1  0.19 0.25 0.07 0.12 0.23 0.26 0.08\n",
            " 0.13 0.16 0.15 0.22 0.1  0.09 0.11 0.19 0.15 0.2  0.1  0.1  0.13 0.17\n",
            " 0.15 0.24]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0.]\n",
            "probs\n",
            "[0.07476636 0.07476636 0.07476636 1.         0.07476636 0.07476636\n",
            " 0.         0.07476636 0.07476636 0.07476636 0.         0.07476636\n",
            " 0.         0.07476636 1.         0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 0.07476636 1.         0.07476636 0.07476636 0.\n",
            " 0.07476636 0.         0.07476636 0.         0.07476636 0.07476636\n",
            " 0.07476636 0.07476636 0.07476636 0.07476636 0.         0.07476636\n",
            " 0.07476636 0.07476636 0.         0.07476636 0.         0.07476636\n",
            " 0.07476636 1.         0.07476636 0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 1.         0.07476636 1.         0.         0.07476636\n",
            " 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 0.07476636 0.         0.07476636 0.07476636 0.07476636\n",
            " 0.         0.07476636 0.         0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636 0.07476636\n",
            " 0.07476636 1.         0.07476636 1.         0.07476636 0.07476636\n",
            " 0.         1.         0.07476636 0.        ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:50:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "probs\n",
            "[4.91494268e-01 1.11091612e-02 9.78997070e-03 2.68411815e-01\n",
            " 6.62212726e-03 6.30483404e-02 1.59455210e-01 4.43311920e-03\n",
            " 5.57948351e-02 6.83723271e-01 9.80056152e-02 1.93099361e-02\n",
            " 7.06301108e-02 9.69069172e-03 1.40572502e-03 2.15162989e-03\n",
            " 8.91415123e-03 9.23804753e-03 6.08229125e-03 9.69880819e-03\n",
            " 8.35751742e-03 1.34903220e-02 4.93953377e-02 6.62148893e-01\n",
            " 2.54352927e-01 1.30947500e-01 1.20498650e-01 1.82396322e-01\n",
            " 2.13855371e-01 7.29857236e-02 7.41784871e-02 6.23708844e-01\n",
            " 1.05761595e-01 7.20600665e-01 9.92151424e-02 8.93766209e-02\n",
            " 6.38210922e-02 4.12816135e-03 7.57905841e-02 1.00953378e-01\n",
            " 2.29436100e-01 3.12486663e-02 4.35725190e-02 3.10363710e-01\n",
            " 8.62779468e-02 8.33143946e-03 9.29373056e-02 1.05534256e-01\n",
            " 5.74134104e-02 2.55049746e-02 2.71607369e-01 6.82036504e-02\n",
            " 1.14878595e-01 1.22770220e-02 1.39970623e-03 3.79296532e-03\n",
            " 1.15847915e-01 3.29699725e-01 2.25303099e-02 1.61894988e-02\n",
            " 7.07570510e-03 4.16394416e-03 2.77081877e-02 9.65788553e-04\n",
            " 2.01451808e-01 4.38805223e-01 3.92590761e-02 6.14347398e-01\n",
            " 6.14397973e-03 1.29056312e-02 9.68885303e-01 2.29982268e-02\n",
            " 2.15260275e-02 9.31254998e-02 2.77374238e-01 2.34620646e-01\n",
            " 1.89438486e-03 1.78279251e-01 9.61465895e-01 4.66015935e-03\n",
            " 5.89193730e-03 2.99129239e-03 6.67678490e-02 3.26435305e-02\n",
            " 1.59696545e-02 2.47941893e-02 2.13072747e-02 3.22200269e-01\n",
            " 3.20762545e-02 2.03791261e-02 2.78198975e-03 3.52556407e-01\n",
            " 4.89188917e-03 1.88993290e-02 1.93668075e-03 2.44653388e-03\n",
            " 2.34943684e-02 2.02706642e-02 1.06440717e-02 1.64767385e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0.]\n",
            "probs\n",
            "[5.79395623e-02 2.93117625e-01 1.24004254e-01 7.71029490e-02\n",
            " 6.10107249e-04 4.30707010e-04 3.94660095e-02 2.72724219e-13\n",
            " 3.34041767e-04 1.61914096e-01 1.07299595e-10 1.12851802e-02\n",
            " 3.41029055e-04 5.47878542e-02 2.42399488e-06 9.92398358e-04\n",
            " 1.84609973e-01 3.07197744e-01 2.72283061e-01 4.99775330e-01\n",
            " 5.41100428e-02 0.00000000e+00 2.39488590e-01 5.49353189e-02\n",
            " 1.25819401e-01 2.46154830e-01 3.61978541e-01 1.77501605e-01\n",
            " 0.00000000e+00 8.15261764e-08 2.15684389e-01 7.59511778e-04\n",
            " 4.21176708e-03 1.07302697e-03 2.54163900e-01 3.98647561e-04\n",
            " 0.00000000e+00 4.24111447e-02 6.64371870e-02 6.88983456e-02\n",
            " 7.40639241e-02 5.74652979e-01 3.56943600e-02 5.51545907e-02\n",
            " 3.26692074e-03 4.04753231e-01 1.31389375e-04 4.34416239e-03\n",
            " 5.33207717e-02 2.81776894e-03 3.61601949e-02 4.78323413e-02\n",
            " 2.93364666e-01 9.35051391e-03 1.78595228e-13 1.81936011e-01\n",
            " 2.27895380e-01 2.68705230e-04 1.62357823e-03 1.52986459e-02\n",
            " 4.00971970e-02 4.26836201e-01 1.00390369e-01 1.12589268e-01\n",
            " 3.23576636e-01 3.83792037e-05 3.76527214e-02 7.87617612e-02\n",
            " 1.52887533e-01 1.67362367e-01 7.41125069e-03 6.91844941e-01\n",
            " 1.89293600e-08 1.00700641e-02 9.22344382e-03 2.52118814e-02\n",
            " 2.35378791e-02 4.74663158e-02 8.46868922e-06 2.91197004e-02\n",
            " 8.34311215e-04 7.24365535e-02 1.66400308e-01 2.86068926e-01\n",
            " 5.10266506e-02 1.19299513e-01 0.00000000e+00 8.76636948e-04\n",
            " 2.15345923e-01 5.84516250e-02 6.81924503e-02 1.79399437e-01\n",
            " 1.46499923e-02 7.21492930e-01 2.22296991e-01 2.60890765e-01\n",
            " 6.09136115e-03 6.72360280e-01 1.47578385e-01 8.70217554e-03]\n",
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.19873074 0.10990182 0.17519723 0.24584535 0.18709398 0.09642945\n",
            " 0.16838092 0.16583317 0.19744187 0.17689382 0.19712336 0.12905662\n",
            " 0.21951847 0.10022111 0.1963017  0.11588137 0.11338079 0.22253361\n",
            " 0.1386039  0.12780902 0.14734757 0.18182139 0.21539755 0.32376939\n",
            " 0.22836606 0.1886315  0.23342781 0.2458822  0.19119166 0.09987191\n",
            " 0.20652184 0.29063926 0.08844394 0.31012339 0.15210583 0.14569061\n",
            " 0.30144657 0.19432942 0.20941321 0.15920977 0.28170048 0.11193273\n",
            " 0.17198793 0.19562288 0.20358421 0.16049528 0.21216803 0.25597838\n",
            " 0.23233509 0.19287572 0.15923264 0.18985347 0.24452148 0.14574265\n",
            " 0.1500691  0.13423954 0.2538779  0.24818584 0.10402453 0.1681443\n",
            " 0.16421025 0.16393815 0.17830304 0.14556223 0.29632803 0.24552255\n",
            " 0.16822305 0.24559374 0.07543265 0.14406396 0.23941378 0.21978952\n",
            " 0.25182838 0.21532884 0.15537338 0.12525469 0.15611523 0.1459163\n",
            " 0.24091494 0.19306949 0.11272722 0.22622651 0.30093634 0.17123846\n",
            " 0.18241775 0.17380313 0.18098027 0.18556767 0.1702099  0.19694906\n",
            " 0.14864902 0.21765995 0.1287479  0.19817929 0.17509711 0.1365542\n",
            " 0.17030231 0.13568998 0.15048488 0.22695141]\n",
            "DecisionTree\n",
            "preds\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.75  0.    0.375 0.25  0.    0.    0.5   0.    0.375 0.75  0.5   0.\n",
            " 0.5   0.    0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.75\n",
            " 0.75  0.    0.25  0.375 0.25  0.5   0.    0.5   0.    0.5   0.    0.\n",
            " 0.    0.    0.75  0.75  0.75  0.    0.    0.75  0.5   0.    0.5   0.75\n",
            " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.75  0.    0.\n",
            " 0.    0.25  0.75  0.25  0.75  0.    0.    0.75  0.    0.375 0.75  0.\n",
            " 0.25  0.75  0.5   0.75  0.    0.75  0.5   0.    0.5   0.    0.    0.\n",
            " 0.75  0.25  0.375 0.75  0.    0.    0.    0.25  0.    0.25  0.    0.\n",
            " 0.5   0.    0.    0.5  ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:50:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "probs\n",
            "[0.28840518 0.1074774  0.16228351 0.2260627  0.0939941  0.11708596\n",
            " 0.21992919 0.09230533 0.18159983 0.26258716 0.13798684 0.11161553\n",
            " 0.15355022 0.10615052 0.08733156 0.11583598 0.09184466 0.16887213\n",
            " 0.14296548 0.11383519 0.17252308 0.09675806 0.22633773 0.28367454\n",
            " 0.20205288 0.21214116 0.17846672 0.18489994 0.09988129 0.13789865\n",
            " 0.20704249 0.33210003 0.1175688  0.3353524  0.21076573 0.16975676\n",
            " 0.1792304  0.09927292 0.1675     0.18247385 0.27152744 0.16073161\n",
            " 0.19935961 0.30647174 0.1388723  0.12492047 0.15313058 0.18441002\n",
            " 0.1865762  0.12796119 0.12619773 0.11505489 0.24599989 0.10446126\n",
            " 0.08428722 0.08958064 0.18664485 0.28373355 0.16769634 0.16446155\n",
            " 0.09870309 0.10951214 0.20850915 0.10061881 0.25166866 0.2126715\n",
            " 0.10024969 0.31855568 0.09166112 0.13097645 0.31631947 0.16577056\n",
            " 0.10515408 0.25302482 0.22599205 0.15868668 0.08699469 0.21959238\n",
            " 0.2851133  0.14400701 0.13314018 0.14563847 0.2061064  0.13696918\n",
            " 0.15806006 0.09066743 0.20668854 0.22584602 0.15693475 0.17687324\n",
            " 0.10711006 0.20633577 0.09252432 0.15297343 0.09132785 0.08878478\n",
            " 0.11588888 0.10255231 0.09411255 0.16612978]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0.]\n",
            "probs\n",
            "[5.79395623e-02 2.93117625e-01 1.24004254e-01 7.71029490e-02\n",
            " 6.10107249e-04 4.30707010e-04 3.94660095e-02 2.72724219e-13\n",
            " 3.34041767e-04 1.61914096e-01 1.07299595e-10 1.12851802e-02\n",
            " 3.41029055e-04 5.47878542e-02 2.42399488e-06 9.92398358e-04\n",
            " 1.84609973e-01 3.07197744e-01 2.72283061e-01 4.99775330e-01\n",
            " 5.41100428e-02 0.00000000e+00 2.39488590e-01 5.49353189e-02\n",
            " 1.25819401e-01 2.46154830e-01 3.61978541e-01 1.77501605e-01\n",
            " 0.00000000e+00 8.15261764e-08 2.15684389e-01 7.59511778e-04\n",
            " 4.21176708e-03 1.07302697e-03 2.54163900e-01 3.98647561e-04\n",
            " 0.00000000e+00 4.24111447e-02 6.64371870e-02 6.88983456e-02\n",
            " 7.40639241e-02 5.74652979e-01 3.56943600e-02 5.51545907e-02\n",
            " 3.26692074e-03 4.04753231e-01 1.31389375e-04 4.34416239e-03\n",
            " 5.33207717e-02 2.81776894e-03 3.61601949e-02 4.78323413e-02\n",
            " 2.93364666e-01 9.35051391e-03 1.78595228e-13 1.81936011e-01\n",
            " 2.27895380e-01 2.68705230e-04 1.62357823e-03 1.52986459e-02\n",
            " 4.00971970e-02 4.26836201e-01 1.00390369e-01 1.12589268e-01\n",
            " 3.23576636e-01 3.83792037e-05 3.76527214e-02 7.87617612e-02\n",
            " 1.52887533e-01 1.67362367e-01 7.41125069e-03 6.91844941e-01\n",
            " 1.89293600e-08 1.00700641e-02 9.22344382e-03 2.52118814e-02\n",
            " 2.35378791e-02 4.74663158e-02 8.46868922e-06 2.91197004e-02\n",
            " 8.34311215e-04 7.24365535e-02 1.66400308e-01 2.86068926e-01\n",
            " 5.10266506e-02 1.19299513e-01 0.00000000e+00 8.76636948e-04\n",
            " 2.15345923e-01 5.84516250e-02 6.81924503e-02 1.79399437e-01\n",
            " 1.46499923e-02 7.21492930e-01 2.22296991e-01 2.60890765e-01\n",
            " 6.09136115e-03 6.72360280e-01 1.47578385e-01 8.70217554e-03]\n",
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.11 0.15 0.24 0.11 0.11 0.14 0.22 0.2  0.15 0.04 0.11 0.12 0.18 0.11\n",
            " 0.09 0.11 0.13 0.26 0.29 0.15 0.07 0.13 0.06 0.24 0.2  0.06 0.18 0.22\n",
            " 0.06 0.15 0.2  0.21 0.11 0.34 0.1  0.2  0.15 0.16 0.1  0.26 0.15 0.14\n",
            " 0.16 0.1  0.17 0.15 0.08 0.05 0.08 0.15 0.1  0.09 0.15 0.12 0.09 0.16\n",
            " 0.19 0.1  0.09 0.11 0.08 0.21 0.22 0.1  0.19 0.13 0.16 0.08 0.15 0.16\n",
            " 0.19 0.29 0.14 0.22 0.16 0.2  0.07 0.09 0.11 0.18 0.12 0.06 0.13 0.21\n",
            " 0.23 0.19 0.18 0.08 0.29 0.13 0.1  0.22 0.07 0.18 0.23 0.08 0.06 0.09\n",
            " 0.1  0.13]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1.]\n",
            "probs\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:50:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
            "probs\n",
            "[5.61467186e-03 4.32530791e-03 1.36484399e-01 3.14164311e-02\n",
            " 4.06370824e-03 2.46592006e-03 8.04577861e-03 6.37863427e-02\n",
            " 1.09621830e-01 7.68739323e-04 7.01683387e-03 6.20211195e-03\n",
            " 5.99517882e-01 3.96240177e-03 1.84169766e-02 8.25607330e-02\n",
            " 5.84099032e-02 1.25004157e-01 1.32629156e-01 7.92812463e-03\n",
            " 3.91729642e-04 1.20906137e-01 1.87157292e-03 6.69355914e-02\n",
            " 2.03282535e-01 1.96652301e-03 1.40578495e-02 2.91303515e-01\n",
            " 1.23473909e-03 2.32218541e-02 5.81134409e-02 1.37469813e-01\n",
            " 2.93491445e-02 3.35318357e-01 3.07758921e-04 2.40923762e-01\n",
            " 3.40456814e-01 4.16120328e-02 3.08846869e-02 5.02983153e-01\n",
            " 8.19778256e-03 2.25485768e-02 1.06729679e-01 4.22086120e-02\n",
            " 1.69921741e-02 1.43115278e-02 1.06719621e-02 7.40962336e-04\n",
            " 9.28134192e-03 1.01076812e-02 1.49894040e-03 8.10911879e-03\n",
            " 6.51353151e-02 1.66247457e-01 4.13329480e-03 1.55738192e-02\n",
            " 4.63666707e-01 3.44065316e-02 2.61506415e-03 6.24020468e-04\n",
            " 8.13981867e-04 3.42204273e-02 1.81033507e-01 2.71536899e-03\n",
            " 3.73821519e-02 4.52786451e-03 4.14254796e-03 9.98009816e-02\n",
            " 1.26809394e-02 1.47847682e-02 1.31211113e-02 2.57825017e-01\n",
            " 1.55980512e-01 5.28351963e-01 4.44735177e-02 2.71431487e-02\n",
            " 1.12960371e-03 1.50574709e-03 1.87705993e-03 3.96949887e-01\n",
            " 3.80517566e-03 1.28916744e-03 6.99232221e-02 5.08421275e-04\n",
            " 9.22788866e-03 9.27257612e-02 7.18214288e-02 8.67189025e-04\n",
            " 7.53136814e-01 4.30790424e-01 1.70025714e-02 2.10329127e-02\n",
            " 5.50507475e-03 4.80825314e-03 6.42117023e-01 4.37866052e-04\n",
            " 2.22066138e-03 1.09521886e-02 5.92118129e-03 3.85868326e-02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[9.41969609e-03 1.86080058e-02 8.88324079e-01 4.00331405e-02\n",
            " 3.48127543e-01 4.50573283e-02 6.97827149e-03 1.32292054e-01\n",
            " 0.00000000e+00 9.36153153e-04 4.41827377e-02 2.69905733e-01\n",
            " 0.00000000e+00 6.06310581e-02 2.27602573e-02 1.05871815e-01\n",
            " 2.56172968e-04 1.51734242e-01 8.59989082e-02 1.30402004e-03\n",
            " 2.67127370e-01 1.22077261e-03 5.04539808e-01 0.00000000e+00\n",
            " 7.74875056e-02 1.03670804e-01 2.18853041e-01 0.00000000e+00\n",
            " 7.36501915e-01 1.92230868e-02 3.18329815e-01 0.00000000e+00\n",
            " 4.28200057e-02 0.00000000e+00 1.86308925e-01 0.00000000e+00\n",
            " 8.12041779e-01 0.00000000e+00 2.76518396e-01 5.82696730e-03\n",
            " 0.00000000e+00 6.46659922e-02 1.72447101e-01 5.57245000e-03\n",
            " 8.46280410e-05 1.19897644e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.44248097e-02 9.01556359e-02 1.30953193e-02\n",
            " 1.43821253e-01 1.14950182e-01 5.83056133e-02 3.40524037e-02\n",
            " 1.48809192e-01 0.00000000e+00 2.28497932e-02 0.00000000e+00\n",
            " 0.00000000e+00 9.32083153e-02 0.00000000e+00 6.05159502e-02\n",
            " 0.00000000e+00 1.26576579e-03 9.11452186e-02 2.40709239e-01\n",
            " 7.07613131e-08 1.26879894e-01 0.00000000e+00 5.13166959e-02\n",
            " 0.00000000e+00 0.00000000e+00 9.83498619e-02 1.13366002e-01\n",
            " 2.37864907e-01 1.13412223e-01 3.21811928e-05 5.51484798e-02\n",
            " 4.25099755e-02 0.00000000e+00 2.61151568e-01 2.17564006e-01\n",
            " 5.55117937e-02 0.00000000e+00 9.20869134e-01 3.50935028e-01\n",
            " 2.69201137e-01 0.00000000e+00 2.10489691e-01 9.56419353e-02\n",
            " 2.21609402e-02 7.21709931e-02 0.00000000e+00 2.18096425e-01\n",
            " 3.16115511e-02 3.47730873e-03 0.00000000e+00 0.00000000e+00]\n",
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.08709363 0.07327544 0.19450055 0.09730303 0.08488006 0.09276895\n",
            " 0.07193772 0.09213259 0.16409668 0.07223282 0.15805827 0.06968021\n",
            " 0.31709019 0.03536702 0.05860228 0.12917984 0.12256513 0.17100127\n",
            " 0.2339937  0.08265273 0.04160878 0.1374329  0.05022416 0.2015222\n",
            " 0.18925452 0.05227544 0.19274359 0.160774   0.06800127 0.22867227\n",
            " 0.26127941 0.17491181 0.08380466 0.22327544 0.10466794 0.10508497\n",
            " 0.17507703 0.13034326 0.08984687 0.21878302 0.25379925 0.05455749\n",
            " 0.15936275 0.09814124 0.20729925 0.05027544 0.06732306 0.07224148\n",
            " 0.07218886 0.07823287 0.1014183  0.05910084 0.14958785 0.21593021\n",
            " 0.04572133 0.10551354 0.20963614 0.07558713 0.14645582 0.10042005\n",
            " 0.07213259 0.10294211 0.16992588 0.07589449 0.29385553 0.04141036\n",
            " 0.12646153 0.13469896 0.11142696 0.09086419 0.12696767 0.2299536\n",
            " 0.17851335 0.27293021 0.06638655 0.10038655 0.04891036 0.09188259\n",
            " 0.07045077 0.18794608 0.07986275 0.02446592 0.1842422  0.10019175\n",
            " 0.19575452 0.15055466 0.1817253  0.02913259 0.22571586 0.12928699\n",
            " 0.06547458 0.09611538 0.07869211 0.09081146 0.24192912 0.07482306\n",
            " 0.07548684 0.0579183  0.09696592 0.14320401]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.  0.  0.  0.5 0.  0.5 0.  0.  0.5 0.  0.  0.  0.5 0.  0.  0.  0.  0.5\n",
            " 0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.\n",
            " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.\n",
            " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            " 0.5 0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.  0.  0.\n",
            " 0.  0.  0.  0.  0.5 0.  0.  0.  0.  0. ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:50:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "probs\n",
            "[0.09554537 0.10832956 0.20383477 0.13987292 0.08372681 0.10865102\n",
            " 0.1329094  0.14172274 0.14429867 0.0862973  0.11352452 0.11318025\n",
            " 0.21836978 0.09284919 0.10684822 0.17769057 0.15662694 0.17811853\n",
            " 0.1714628  0.11805993 0.08946126 0.16248673 0.11421359 0.14817706\n",
            " 0.17270711 0.10455021 0.17598835 0.16544552 0.10917381 0.11703147\n",
            " 0.17552266 0.13000545 0.1736392  0.16731362 0.08607656 0.13152923\n",
            " 0.13590544 0.16277136 0.16102792 0.20840922 0.12000892 0.12758936\n",
            " 0.16106264 0.12842919 0.12473316 0.15550065 0.12793235 0.08999237\n",
            " 0.11817767 0.1012353  0.08694198 0.09704576 0.21035877 0.17877673\n",
            " 0.09708738 0.1363182  0.25334486 0.1272276  0.09678625 0.102419\n",
            " 0.11398769 0.15085381 0.20138748 0.09659174 0.13517372 0.09430923\n",
            " 0.1289837  0.20184535 0.10791687 0.13281912 0.15581274 0.20945372\n",
            " 0.13410722 0.21984234 0.16096601 0.11874868 0.11521342 0.09847733\n",
            " 0.08952543 0.20478137 0.11482937 0.10078924 0.19399643 0.09711396\n",
            " 0.15809448 0.14997673 0.15304406 0.08070706 0.25475174 0.18723667\n",
            " 0.12274923 0.12775585 0.11683139 0.1265927  0.21527056 0.09358408\n",
            " 0.08684144 0.10502721 0.10784762 0.12449685]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[9.41969609e-03 1.86080058e-02 8.88324079e-01 4.00331405e-02\n",
            " 3.48127543e-01 4.50573283e-02 6.97827149e-03 1.32292054e-01\n",
            " 0.00000000e+00 9.36153153e-04 4.41827377e-02 2.69905733e-01\n",
            " 0.00000000e+00 6.06310581e-02 2.27602573e-02 1.05871815e-01\n",
            " 2.56172968e-04 1.51734242e-01 8.59989082e-02 1.30402004e-03\n",
            " 2.67127370e-01 1.22077261e-03 5.04539808e-01 0.00000000e+00\n",
            " 7.74875056e-02 1.03670804e-01 2.18853041e-01 0.00000000e+00\n",
            " 7.36501915e-01 1.92230868e-02 3.18329815e-01 0.00000000e+00\n",
            " 4.28200057e-02 0.00000000e+00 1.86308925e-01 0.00000000e+00\n",
            " 8.12041779e-01 0.00000000e+00 2.76518396e-01 5.82696730e-03\n",
            " 0.00000000e+00 6.46659922e-02 1.72447101e-01 5.57245000e-03\n",
            " 8.46280410e-05 1.19897644e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.44248097e-02 9.01556359e-02 1.30953193e-02\n",
            " 1.43821253e-01 1.14950182e-01 5.83056133e-02 3.40524037e-02\n",
            " 1.48809192e-01 0.00000000e+00 2.28497932e-02 0.00000000e+00\n",
            " 0.00000000e+00 9.32083153e-02 0.00000000e+00 6.05159502e-02\n",
            " 0.00000000e+00 1.26576579e-03 9.11452186e-02 2.40709239e-01\n",
            " 7.07613131e-08 1.26879894e-01 0.00000000e+00 5.13166959e-02\n",
            " 0.00000000e+00 0.00000000e+00 9.83498619e-02 1.13366002e-01\n",
            " 2.37864907e-01 1.13412223e-01 3.21811928e-05 5.51484798e-02\n",
            " 4.25099755e-02 0.00000000e+00 2.61151568e-01 2.17564006e-01\n",
            " 5.55117937e-02 0.00000000e+00 9.20869134e-01 3.50935028e-01\n",
            " 2.69201137e-01 0.00000000e+00 2.10489691e-01 9.56419353e-02\n",
            " 2.21609402e-02 7.21709931e-02 0.00000000e+00 2.18096425e-01\n",
            " 3.16115511e-02 3.47730873e-03 0.00000000e+00 0.00000000e+00]\n",
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.07 0.11 0.08 0.28 0.15 0.24 0.14 0.13 0.18 0.16 0.17 0.07 0.15 0.09\n",
            " 0.21 0.09 0.17 0.11 0.15 0.32 0.07 0.27 0.1  0.15 0.12 0.07 0.22 0.16\n",
            " 0.28 0.16 0.17 0.29 0.15 0.23 0.13 0.12 0.25 0.13 0.16 0.11 0.09 0.18\n",
            " 0.19 0.08 0.13 0.12 0.23 0.17 0.09 0.15 0.12 0.25 0.14 0.14 0.31 0.11\n",
            " 0.18 0.13 0.14 0.13 0.24 0.13 0.08 0.16 0.07 0.22 0.21 0.14 0.16 0.14\n",
            " 0.25 0.13 0.16 0.13 0.1  0.13 0.18 0.12 0.15 0.16 0.12 0.09 0.1  0.1\n",
            " 0.16 0.18 0.2  0.19 0.14 0.18 0.09 0.23 0.12 0.28 0.12 0.14 0.17 0.25\n",
            " 0.11 0.13]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.09638554 0.09638554 0.09638554 0.         0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.         0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554 0.09638554\n",
            " 0.09638554 0.         0.09638554 0.         0.09638554 0.09638554\n",
            " 0.09638554 0.09638554 0.09638554 0.09638554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:50:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "probs\n",
            "[9.08774149e-04 6.09151379e-04 5.85050147e-04 4.05345894e-02\n",
            " 2.84819189e-03 4.11677659e-01 2.11542146e-03 4.68810834e-03\n",
            " 5.66503638e-03 2.11379789e-02 1.22092582e-01 3.25970054e-02\n",
            " 2.60881096e-01 7.36494362e-03 5.84841613e-03 4.44931909e-02\n",
            " 8.00116360e-02 5.69426501e-03 1.15674675e-01 2.02112764e-01\n",
            " 1.70254742e-03 1.18285164e-01 1.48029570e-02 4.63420554e-04\n",
            " 4.84406948e-03 2.68807113e-02 9.76354539e-01 3.05227578e-01\n",
            " 6.34385794e-02 4.39130468e-03 1.91079881e-02 3.71708423e-02\n",
            " 6.70230165e-02 5.49137825e-04 5.57832466e-03 1.18464103e-03\n",
            " 1.11787794e-02 1.42835465e-03 2.80659436e-03 3.02615133e-03\n",
            " 3.65757104e-03 3.69124822e-02 4.76393662e-02 1.17217412e-03\n",
            " 4.10617003e-03 1.71993382e-03 8.68153498e-02 1.08019579e-02\n",
            " 7.50693376e-04 1.24098165e-02 1.36763960e-01 6.89018741e-02\n",
            " 9.40833688e-02 1.83704823e-01 5.94703779e-02 2.31926404e-02\n",
            " 4.42717969e-03 1.25859501e-02 7.92544708e-03 7.54074380e-03\n",
            " 1.59052476e-01 9.65238363e-02 5.45517833e-04 2.06460841e-02\n",
            " 7.62094511e-04 1.55638787e-03 6.27230341e-03 5.81362564e-03\n",
            " 7.91092345e-04 1.19064063e-01 4.86127645e-01 1.65930297e-02\n",
            " 6.30846154e-03 1.84441940e-03 1.45791452e-02 7.42953420e-02\n",
            " 1.80947054e-02 9.05788317e-03 1.00091830e-01 6.07298454e-03\n",
            " 4.81791236e-03 1.30748451e-02 1.29800499e-03 6.72458485e-03\n",
            " 7.20765488e-03 6.87357903e-01 4.94554965e-03 2.18736548e-02\n",
            " 9.98854823e-03 6.16052002e-03 6.18990918e-04 1.50130773e-02\n",
            " 1.98098435e-03 1.75714701e-01 8.44843984e-02 2.76280623e-02\n",
            " 1.05251506e-01 2.40001548e-03 6.62576407e-03 2.46597398e-02]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-984bbad0de11>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Evaluate without hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     results_no_tuning = evaluate_models_with_tuning(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_ohe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-259b1c663e70>\u001b[0m in \u001b[0;36mevaluate_models_with_tuning\u001b[0;34m(train_ohe, train_label, train_lr, test_ohe_100, test_label_100, test_lr_100, sizes, random_state, hyperparameter_tuning)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Train and evaluate logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Logistic regression always outputs two classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             ]\n\u001b[0;32m--> 455\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                  **options)\n\u001b[1;32m    712\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    714\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    715\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mgrad_pointwise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_reg_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_pointwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.to_csv('/content/drive/MyDrive/Indian_bank_data/traiditional_ML_results.csv', index=False)"
      ],
      "metadata": {
        "id": "UAKOjrebHw2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "5Gagsal9J5eb",
        "outputId": "fbafdf76-e31b-4ec8-90e6-f07081e2c70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Model  Train Size        F1    ROCAUC     PRAUC  Iteration  \\\n",
              "0          RandomForest           8  0.000000  0.316534  0.102627          1   \n",
              "1          DecisionTree           8  0.000000  0.500000  0.130000          1   \n",
              "2               XGBoost           8  0.000000  0.500000  0.130000          1   \n",
              "3    LogisticRegression           8  0.200000  0.607869  0.189695          1   \n",
              "4          RandomForest          16  0.000000  0.359859  0.110378          1   \n",
              "..                  ...         ...       ...       ...       ...        ...   \n",
              "395  LogisticRegression          64  0.230769  0.558355  0.254256         10   \n",
              "396        RandomForest         128  0.000000  0.641026  0.181287         10   \n",
              "397        DecisionTree         128  0.263158  0.588417  0.176154         10   \n",
              "398             XGBoost         128  0.111111  0.497790  0.190122         10   \n",
              "399  LogisticRegression         128  0.100000  0.385057  0.123451         10   \n",
              "\n",
              "    Tuning  \n",
              "0       No  \n",
              "1       No  \n",
              "2       No  \n",
              "3       No  \n",
              "4       No  \n",
              "..     ...  \n",
              "395    Yes  \n",
              "396    Yes  \n",
              "397    Yes  \n",
              "398    Yes  \n",
              "399    Yes  \n",
              "\n",
              "[400 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-050e9f0e-8683-416a-8f5d-a9e8420e9701\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train Size</th>\n",
              "      <th>F1</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>PRAUC</th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Tuning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.316534</td>\n",
              "      <td>0.102627</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>8</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.607869</td>\n",
              "      <td>0.189695</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.359859</td>\n",
              "      <td>0.110378</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>64</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.558355</td>\n",
              "      <td>0.254256</td>\n",
              "      <td>10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.181287</td>\n",
              "      <td>10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>128</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.588417</td>\n",
              "      <td>0.176154</td>\n",
              "      <td>10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>128</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.497790</td>\n",
              "      <td>0.190122</td>\n",
              "      <td>10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>128</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.385057</td>\n",
              "      <td>0.123451</td>\n",
              "      <td>10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-050e9f0e-8683-416a-8f5d-a9e8420e9701')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-050e9f0e-8683-416a-8f5d-a9e8420e9701 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-050e9f0e-8683-416a-8f5d-a9e8420e9701');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2887be7-ffc8-462b-9abf-73afb17b9104\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2887be7-ffc8-462b-9abf-73afb17b9104')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2887be7-ffc8-462b-9abf-73afb17b9104 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5382eeff-d4f0-48b4-a7e3-81779ad91f6d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5382eeff-d4f0-48b4-a7e3-81779ad91f6d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_results",
              "summary": "{\n  \"name\": \"final_results\",\n  \"rows\": 400,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"DecisionTree\",\n          \"LogisticRegression\",\n          \"RandomForest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43,\n        \"min\": 8,\n        \"max\": 128,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          16,\n          128,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09972665265004187,\n        \"min\": 0.0,\n        \"max\": 0.38596491228070173,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          0.0,\n          0.11764705882352941,\n          0.1935483870967742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROCAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10357141104156524,\n        \"min\": 0.2462422634836428,\n        \"max\": 0.7661361626878869,\n        \"num_unique_values\": 247,\n        \"samples\": [\n          0.45004420866489836,\n          0.5291777188328912,\n          0.6525198938992042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.059719553207997884,\n        \"min\": 0.08898626396555456,\n        \"max\": 0.462317575158064,\n        \"num_unique_values\": 261,\n        \"samples\": [\n          0.13100676848518739,\n          0.18484783810151983,\n          0.1656694791543737\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tuning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.groupby([\"Model\", \"Tuning\", \"Train Size\"]).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uhFMUilKJ6do",
        "outputId": "4c85b925-55fc-4904-c58a-b688a622154b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            F1    ROCAUC     PRAUC  Iteration\n",
              "Model              Tuning Train Size                                         \n",
              "DecisionTree       No     8           0.084405  0.505747  0.137094        5.5\n",
              "                          16          0.054040  0.480592  0.136000        5.5\n",
              "                          32          0.093360  0.497701  0.133870        5.5\n",
              "                          64          0.073252  0.485455  0.134953        5.5\n",
              "                          128         0.132694  0.499602  0.136777        5.5\n",
              "                   Yes    8           0.000000  0.500000  0.130000        5.5\n",
              "                          16          0.000000  0.520336  0.147548        5.5\n",
              "                          32          0.045652  0.530592  0.142386        5.5\n",
              "                          64          0.081705  0.497657  0.141580        5.5\n",
              "                          128         0.094865  0.497038  0.142852        5.5\n",
              "LogisticRegression No     8           0.253362  0.597215  0.200022        5.5\n",
              "                          16          0.201326  0.529310  0.211544        5.5\n",
              "                          32          0.113592  0.376569  0.177702        5.5\n",
              "                          64          0.115729  0.450575  0.190337        5.5\n",
              "                          128         0.092260  0.462025  0.168424        5.5\n",
              "                   Yes    8           0.253362  0.597215  0.200022        5.5\n",
              "                          16          0.201326  0.529310  0.211544        5.5\n",
              "                          32          0.113592  0.376569  0.177702        5.5\n",
              "                          64          0.115729  0.450575  0.190337        5.5\n",
              "                          128         0.092260  0.462025  0.168424        5.5\n",
              "RandomForest       No     8           0.000000  0.531123  0.161334        5.5\n",
              "                          16          0.000000  0.542352  0.156961        5.5\n",
              "                          32          0.000000  0.528205  0.174340        5.5\n",
              "                          64          0.014286  0.529089  0.178624        5.5\n",
              "                          128         0.000000  0.550000  0.195730        5.5\n",
              "                   Yes    8           0.000000  0.500000  0.130000        5.5\n",
              "                          16          0.000000  0.471397  0.151625        5.5\n",
              "                          32          0.000000  0.524226  0.197860        5.5\n",
              "                          64          0.000000  0.485102  0.157079        5.5\n",
              "                          128         0.000000  0.523077  0.169660        5.5\n",
              "XGBoost            No     8           0.000000  0.500000  0.130000        5.5\n",
              "                          16          0.000000  0.464545  0.136762        5.5\n",
              "                          32          0.041863  0.442971  0.149276        5.5\n",
              "                          64          0.047235  0.490407  0.146227        5.5\n",
              "                          128         0.058952  0.500531  0.157032        5.5\n",
              "                   Yes    8           0.000000  0.500000  0.130000        5.5\n",
              "                          16          0.000000  0.493457  0.129427        5.5\n",
              "                          32          0.023810  0.465606  0.151868        5.5\n",
              "                          64          0.019048  0.468612  0.148889        5.5\n",
              "                          128         0.052822  0.504819  0.172024        5.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-109ddf49-8ab7-4865-bf3a-15657e1ff4e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>PRAUC</th>\n",
              "      <th>Iteration</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th>Tuning</th>\n",
              "      <th>Train Size</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">DecisionTree</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <td>0.084405</td>\n",
              "      <td>0.505747</td>\n",
              "      <td>0.137094</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.054040</td>\n",
              "      <td>0.480592</td>\n",
              "      <td>0.136000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.093360</td>\n",
              "      <td>0.497701</td>\n",
              "      <td>0.133870</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.073252</td>\n",
              "      <td>0.485455</td>\n",
              "      <td>0.134953</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.132694</td>\n",
              "      <td>0.499602</td>\n",
              "      <td>0.136777</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520336</td>\n",
              "      <td>0.147548</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.045652</td>\n",
              "      <td>0.530592</td>\n",
              "      <td>0.142386</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.081705</td>\n",
              "      <td>0.497657</td>\n",
              "      <td>0.141580</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.094865</td>\n",
              "      <td>0.497038</td>\n",
              "      <td>0.142852</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">LogisticRegression</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <td>0.253362</td>\n",
              "      <td>0.597215</td>\n",
              "      <td>0.200022</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.201326</td>\n",
              "      <td>0.529310</td>\n",
              "      <td>0.211544</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.113592</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.177702</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.115729</td>\n",
              "      <td>0.450575</td>\n",
              "      <td>0.190337</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.092260</td>\n",
              "      <td>0.462025</td>\n",
              "      <td>0.168424</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <td>0.253362</td>\n",
              "      <td>0.597215</td>\n",
              "      <td>0.200022</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.201326</td>\n",
              "      <td>0.529310</td>\n",
              "      <td>0.211544</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.113592</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.177702</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.115729</td>\n",
              "      <td>0.450575</td>\n",
              "      <td>0.190337</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.092260</td>\n",
              "      <td>0.462025</td>\n",
              "      <td>0.168424</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">RandomForest</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531123</td>\n",
              "      <td>0.161334</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.542352</td>\n",
              "      <td>0.156961</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.528205</td>\n",
              "      <td>0.174340</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.014286</td>\n",
              "      <td>0.529089</td>\n",
              "      <td>0.178624</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.195730</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471397</td>\n",
              "      <td>0.151625</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.524226</td>\n",
              "      <td>0.197860</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.485102</td>\n",
              "      <td>0.157079</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.169660</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">XGBoost</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.464545</td>\n",
              "      <td>0.136762</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.041863</td>\n",
              "      <td>0.442971</td>\n",
              "      <td>0.149276</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.047235</td>\n",
              "      <td>0.490407</td>\n",
              "      <td>0.146227</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.058952</td>\n",
              "      <td>0.500531</td>\n",
              "      <td>0.157032</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.493457</td>\n",
              "      <td>0.129427</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.465606</td>\n",
              "      <td>0.151868</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.019048</td>\n",
              "      <td>0.468612</td>\n",
              "      <td>0.148889</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.052822</td>\n",
              "      <td>0.504819</td>\n",
              "      <td>0.172024</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-109ddf49-8ab7-4865-bf3a-15657e1ff4e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-109ddf49-8ab7-4865-bf3a-15657e1ff4e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-109ddf49-8ab7-4865-bf3a-15657e1ff4e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea26ce1f-2364-4465-ade7-97822cb68aa6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea26ce1f-2364-4465-ade7-97822cb68aa6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea26ce1f-2364-4465-ade7-97822cb68aa6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"final_results\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07113623930026831,\n        \"min\": 0.0,\n        \"max\": 0.25336231111016916,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.08440494978479196,\n          0.05895224171539961,\n          0.041862745098039215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROCAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04422293717564805,\n        \"min\": 0.3765694076038904,\n        \"max\": 0.5972148541114058,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.46560565870910703,\n          0.5311229000884173,\n          0.4645446507515473\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02498349314366989,\n        \"min\": 0.12942736024021903,\n        \"max\": 0.21154368774548407,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.15186833975931746,\n          0.1613336504060998,\n          0.13676185255243778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.5,\n        \"max\": 5.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models_with_tuning_adjusted_proportion(\n",
        "    train_ohe,\n",
        "    train_label,\n",
        "    train_lr,\n",
        "    test_ohe_100,\n",
        "    test_label_100,\n",
        "    test_lr_100,\n",
        "    sizes,\n",
        "    minority_proportions,\n",
        "    random_state=42,\n",
        "    hyperparameter_tuning=False\n",
        "):\n",
        "    from sklearn.utils import resample\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Define hyperparameter grids\n",
        "    param_grids = {\n",
        "        \"RandomForest\": {\n",
        "            \"n_estimators\": [10, 50, 100, 200],\n",
        "            \"max_depth\": [None, 10, 20, 30],\n",
        "            \"min_samples_split\": [2, 5, 10],\n",
        "            \"min_samples_leaf\": [1, 2, 4],\n",
        "        },\n",
        "        \"DecisionTree\": {\n",
        "            \"max_depth\": [None, 10, 20, 30],\n",
        "            \"min_samples_split\": [2, 5, 10],\n",
        "            \"min_samples_leaf\": [1, 2, 4],\n",
        "        },\n",
        "        \"XGBoost\": {\n",
        "            \"n_estimators\": [50, 100, 200],\n",
        "            \"max_depth\": [3, 5, 10],\n",
        "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "            \"subsample\": [0.6, 0.8, 1.0],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Iterate over minority proportions\n",
        "    for minority_proportion in minority_proportions:\n",
        "        # Iterate over training sizes\n",
        "        for size in sizes:\n",
        "            # Separate majority and minority classes\n",
        "            majority = train_ohe[train_ohe[\"Approved_Flag\"] == 0]\n",
        "            minority = train_ohe[train_ohe[\"Approved_Flag\"] == 1]\n",
        "\n",
        "            # Calculate the number of samples needed for each class\n",
        "            n_minority = int(size * minority_proportion)\n",
        "            n_majority = size - n_minority\n",
        "\n",
        "            # Sample data\n",
        "            sampled_minority = resample(minority, replace=True, n_samples=n_minority, random_state=random_state)\n",
        "            sampled_majority = resample(majority, replace=True, n_samples=n_majority, random_state=random_state)\n",
        "            sampled_train_ohe = pd.concat([sampled_minority, sampled_majority])\n",
        "\n",
        "            majority = train_lr[train_lr[\"Approved_Flag\"] == 0]\n",
        "            minority = train_lr[train_lr[\"Approved_Flag\"] == 1]\n",
        "\n",
        "            # Calculate the number of samples needed for each class\n",
        "            n_minority = int(size * minority_proportion)\n",
        "            n_majority = size - n_minority\n",
        "\n",
        "            # Sample data\n",
        "            sampled_minority = resample(minority, replace=True, n_samples=n_minority, random_state=random_state)\n",
        "            sampled_majority = resample(majority, replace=True, n_samples=n_majority, random_state=random_state)\n",
        "            sampled_train_lr = pd.concat([sampled_minority, sampled_majority])\n",
        "\n",
        "            # Split features and labels\n",
        "            X_train_tree = sampled_train_ohe.drop(columns=\"Approved_Flag\")\n",
        "            y_train_tree = sampled_train_ohe[\"Approved_Flag\"]\n",
        "            X_train_lr = sampled_train_lr.drop(columns=\"Approved_Flag\")\n",
        "            y_train_lr = sampled_train_lr[\"Approved_Flag\"]\n",
        "\n",
        "            X_test_tree = test_ohe_100.drop(columns=\"Approved_Flag\")\n",
        "            y_test_tree = test_ohe_100[\"Approved_Flag\"]\n",
        "            X_test_lr = test_lr_100.drop(columns=\"Approved_Flag\")\n",
        "            y_test_lr = test_lr_100[\"Approved_Flag\"]\n",
        "\n",
        "            # Models\n",
        "            models_tree = {\n",
        "                \"RandomForest\": RandomForestClassifier(),\n",
        "                \"DecisionTree\": DecisionTreeClassifier(max_depth = int(math.log2(len(X_train_tree)))),\n",
        "                \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "            }\n",
        "            model_lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "            # Train and evaluate tree-based models\n",
        "            for model_name, model in models_tree.items():\n",
        "                if hyperparameter_tuning:\n",
        "                    # Perform RandomizedSearchCV\n",
        "                    search = RandomizedSearchCV(\n",
        "                        estimator=model,\n",
        "                        param_distributions=param_grids[model_name],\n",
        "                        n_iter=10,\n",
        "                        scoring=\"roc_auc\",\n",
        "                        cv=3,\n",
        "                        random_state=42,\n",
        "                        n_jobs=-1\n",
        "                    )\n",
        "                    search.fit(X_train_tree, y_train_tree)\n",
        "                    model = search.best_estimator_\n",
        "                else:\n",
        "                    model.fit(X_train_tree, y_train_tree)\n",
        "\n",
        "                preds = model.predict(X_test_tree)\n",
        "                if hasattr(model, \"predict_proba\"):\n",
        "                    probs = model.predict_proba(X_test_tree)\n",
        "                    if probs.shape[1] > 1:\n",
        "                        probs = probs[:, 1]  # Take probabilities of the positive class\n",
        "                    else:\n",
        "                        probs = probs[:, 0]  # Single column output\n",
        "                else:\n",
        "                    # Use predictions as probabilities for models without `predict_proba`\n",
        "                    probs = preds\n",
        "                print(model_name)\n",
        "                print(\"preds\")\n",
        "                print(preds)\n",
        "                print(\"probs\")\n",
        "                print(probs)\n",
        "                results.append({\n",
        "                    \"Model\": model_name,\n",
        "                    \"Train Size\": size,\n",
        "                    \"Class 1 Proportion\": minority_proportion,\n",
        "                    \"F1_Score\": f1_score(y_test_lr, preds),\n",
        "                    \"ROC_AUC\": roc_auc_score(y_test_lr, probs),\n",
        "                    \"PR_AUC\": average_precision_score(y_test_lr, probs)\n",
        "                })\n",
        "\n",
        "            # Train and evaluate logistic regression\n",
        "            model_lr.fit(X_train_lr, y_train_lr)\n",
        "            preds = model_lr.predict(X_test_lr)\n",
        "            probs = model_lr.predict_proba(X_test_lr)[:, 1]  # Logistic regression always outputs two classes\n",
        "            results.append({\n",
        "                \"Model\": \"LogisticRegression\",\n",
        "                \"Train Size\": size,\n",
        "                \"Class 1 Proportion\": minority_proportion,\n",
        "                \"F1_Score\": f1_score(y_test_lr, preds),\n",
        "                \"ROC_AUC\": roc_auc_score(y_test_lr, probs),\n",
        "                \"PR_AUC\": average_precision_score(y_test_lr, probs)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "zkiKmc1cLF4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store results\n",
        "all_results = []\n",
        "train_sizes = [32, 64, 128]\n",
        "# Define number of repetitions\n",
        "n_repeats = 10\n",
        "\n",
        "# Run evaluation 10 times for both without and with hyperparameter tuning\n",
        "for i in range(n_repeats):\n",
        "    # Evaluate without hyperparameter tuning\n",
        "    results_no_tuning = evaluate_models_with_tuning_adjusted_proportion(\n",
        "        train_ohe,\n",
        "        train_label,\n",
        "        train_lr,\n",
        "        test_ohe_100,\n",
        "        test_label_100,\n",
        "        test_lr_100,\n",
        "        train_sizes,\n",
        "        [0.3, 0.5],\n",
        "        random_state=i,\n",
        "        hyperparameter_tuning=False\n",
        "    )\n",
        "    # Add iteration number and tuning type\n",
        "    results_no_tuning[\"Iteration\"] = i + 1\n",
        "    results_no_tuning[\"Tuning\"] = \"No\"\n",
        "\n",
        "    # Evaluate with hyperparameter tuning\n",
        "    results_with_tuning = evaluate_models_with_tuning_adjusted_proportion(\n",
        "        train_ohe,\n",
        "        train_label,\n",
        "        train_lr,\n",
        "        test_ohe_100,\n",
        "        test_label_100,\n",
        "        test_lr_100,\n",
        "        train_sizes,\n",
        "        [0.3, 0.5],\n",
        "        random_state=i,\n",
        "        hyperparameter_tuning=True\n",
        "    )\n",
        "    # Add iteration number and tuning type\n",
        "    results_with_tuning[\"Iteration\"] = i + 1\n",
        "    results_with_tuning[\"Tuning\"] = \"Yes\"\n",
        "\n",
        "    # Append both results to the list\n",
        "    all_results.append(results_no_tuning)\n",
        "    all_results.append(results_with_tuning)\n",
        "\n",
        "# Combine all results into a single DataFrame\n",
        "final_results = pd.concat(all_results, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EDwwLmwVL9Eg",
        "outputId": "630c5292-03e0-4a69-8b6d-681dcdba97cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.31 0.2  0.35 0.3  0.28 0.28 0.24 0.23 0.34 0.35 0.31 0.43 0.25 0.25\n",
            " 0.27 0.18 0.26 0.32 0.15 0.2  0.33 0.48 0.26 0.51 0.31 0.27 0.24 0.4\n",
            " 0.4  0.26 0.19 0.44 0.18 0.44 0.25 0.29 0.42 0.39 0.5  0.38 0.41 0.21\n",
            " 0.16 0.33 0.41 0.4  0.4  0.47 0.47 0.23 0.24 0.18 0.32 0.25 0.27 0.33\n",
            " 0.2  0.32 0.24 0.19 0.43 0.15 0.41 0.2  0.44 0.39 0.21 0.25 0.28 0.18\n",
            " 0.25 0.2  0.35 0.35 0.29 0.25 0.4  0.25 0.43 0.18 0.29 0.43 0.34 0.23\n",
            " 0.3  0.31 0.2  0.35 0.21 0.23 0.32 0.24 0.29 0.18 0.3  0.47 0.19 0.3\n",
            " 0.39 0.42]\n",
            "DecisionTree\n",
            "preds\n",
            "[1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1.\n",
            " 0. 0. 1. 1.]\n",
            "probs\n",
            "[1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1.\n",
            " 0. 0. 1. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:55:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0\n",
            " 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1\n",
            " 1 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "probs\n",
            "[0.01985428 0.2631648  0.88553274 0.09814141 0.0868675  0.03553579\n",
            " 0.45171055 0.34271798 0.97550356 0.5408521  0.05412148 0.25580734\n",
            " 0.01761309 0.17904133 0.00511659 0.46697593 0.5595571  0.26518604\n",
            " 0.00705142 0.02566805 0.40820596 0.86894166 0.03063422 0.7174472\n",
            " 0.01911821 0.05711358 0.02563405 0.9779154  0.64799273 0.00449616\n",
            " 0.00680419 0.37040442 0.01491363 0.7608486  0.02188049 0.12889086\n",
            " 0.19968511 0.50015074 0.28922176 0.61531365 0.7365059  0.41347548\n",
            " 0.0079863  0.01970714 0.56972164 0.8727063  0.35185346 0.33678094\n",
            " 0.4550718  0.18147837 0.04938785 0.00405913 0.2304483  0.05074798\n",
            " 0.02913592 0.70297027 0.01687947 0.0161711  0.08956963 0.04140698\n",
            " 0.5408521  0.13923284 0.54468566 0.00650204 0.8789666  0.558757\n",
            " 0.05619578 0.01430679 0.46065181 0.03919563 0.2867589  0.00870182\n",
            " 0.65038013 0.6085602  0.63482416 0.00922063 0.48601785 0.06569974\n",
            " 0.7968513  0.04422763 0.01970714 0.86050737 0.02669743 0.01774572\n",
            " 0.04705141 0.8478198  0.66866404 0.91743916 0.03919563 0.03205283\n",
            " 0.03226229 0.288868   0.0800549  0.04734153 0.16585588 0.4644426\n",
            " 0.02609052 0.3239263  0.4644426  0.7365059 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0.]\n",
            "probs\n",
            "[3.68444882e-02 1.57299486e-02 3.18069547e-04 1.66748831e-04\n",
            " 7.68990420e-03 5.97888968e-06 1.18136899e-01 1.43893035e-03\n",
            " 9.97503044e-01 5.31899930e-02 4.20823121e-04 5.15518166e-05\n",
            " 1.21505414e-02 8.53337997e-03 2.68872037e-02 9.65779139e-04\n",
            " 9.19525625e-01 2.11189946e-01 2.02298200e-01 2.84550987e-10\n",
            " 3.11900283e-03 0.00000000e+00 1.44599538e-01 1.18944721e-01\n",
            " 5.93489679e-02 3.48522671e-01 1.86734680e-01 3.26247294e-01\n",
            " 0.00000000e+00 1.12286498e-03 2.05512072e-01 9.97022882e-01\n",
            " 4.96674543e-04 9.99976744e-01 5.86331036e-01 9.99548684e-01\n",
            " 0.00000000e+00 5.33811947e-05 4.95660777e-02 3.05236160e-03\n",
            " 1.27652546e-01 1.84611131e-01 1.47080431e-04 1.20464834e-02\n",
            " 9.97875322e-01 2.74820476e-01 1.07352252e-02 9.74060643e-01\n",
            " 6.51668102e-01 8.36606351e-01 1.89740787e-03 2.62349266e-04\n",
            " 1.73481736e-01 1.30220185e-03 8.44120956e-08 1.58572124e-02\n",
            " 8.30593742e-02 4.77753578e-01 7.90022674e-04 9.77896529e-01\n",
            " 2.32766729e-04 1.96693567e-02 7.01690260e-01 2.14909806e-02\n",
            " 3.83440100e-03 3.06915010e-04 7.79857891e-03 4.39742769e-02\n",
            " 9.99838622e-01 5.94404104e-01 2.25080324e-01 4.25660596e-03\n",
            " 9.97585158e-01 9.31591868e-01 8.09615811e-03 1.39675230e-02\n",
            " 3.28328780e-01 7.97503261e-02 2.37981185e-02 1.58644340e-01\n",
            " 2.54745195e-02 9.91190429e-01 2.22834148e-01 1.50425692e-01\n",
            " 2.94746214e-02 9.17626747e-01 0.00000000e+00 2.32108884e-01\n",
            " 1.09381867e-01 8.94358264e-03 5.24191168e-04 3.49793251e-07\n",
            " 1.67799662e-02 2.27617739e-03 8.39078872e-01 2.72529452e-01\n",
            " 1.06201916e-03 2.41746414e-08 9.61418240e-01 4.35836919e-03]\n",
            "RandomForest\n",
            "preds\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "probs\n",
            "[0.24 0.29 0.37 0.3  0.27 0.33 0.26 0.26 0.31 0.28 0.35 0.4  0.27 0.33\n",
            " 0.3  0.35 0.34 0.27 0.28 0.32 0.27 0.42 0.29 0.4  0.4  0.22 0.24 0.45\n",
            " 0.47 0.33 0.29 0.37 0.3  0.36 0.21 0.35 0.45 0.44 0.43 0.39 0.24 0.21\n",
            " 0.28 0.27 0.32 0.43 0.45 0.48 0.37 0.38 0.24 0.29 0.41 0.25 0.41 0.47\n",
            " 0.26 0.28 0.31 0.2  0.33 0.26 0.36 0.35 0.35 0.51 0.21 0.34 0.35 0.28\n",
            " 0.27 0.27 0.35 0.35 0.39 0.33 0.46 0.22 0.42 0.21 0.27 0.34 0.33 0.25\n",
            " 0.41 0.32 0.23 0.34 0.27 0.16 0.29 0.3  0.26 0.28 0.26 0.39 0.42 0.33\n",
            " 0.27 0.24]\n",
            "DecisionTree\n",
            "preds\n",
            "[0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0.]\n",
            "probs\n",
            "[0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [03:55:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "preds\n",
            "[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
            "probs\n",
            "[0.03091012 0.0057664  0.74870706 0.05459811 0.28224462 0.30766013\n",
            " 0.02194947 0.02291574 0.08657011 0.52875453 0.4060276  0.11568608\n",
            " 0.08640945 0.41608715 0.18238746 0.49995202 0.01315264 0.3706305\n",
            " 0.02048416 0.21340348 0.09837752 0.07388219 0.03024046 0.52964973\n",
            " 0.25109965 0.02415079 0.05644441 0.22748156 0.37234858 0.20369962\n",
            " 0.03875495 0.59989375 0.01673273 0.09925216 0.02879313 0.17897747\n",
            " 0.0498778  0.8255976  0.04056026 0.64984745 0.11967008 0.44073978\n",
            " 0.05544854 0.05598412 0.23748404 0.7808842  0.22024965 0.34774187\n",
            " 0.22575116 0.04492358 0.01805218 0.03453641 0.63726276 0.13431679\n",
            " 0.26956987 0.8482185  0.00571681 0.12468947 0.20204605 0.09082624\n",
            " 0.52893126 0.10740685 0.72197545 0.08165183 0.06519756 0.6728877\n",
            " 0.04203279 0.85138655 0.28046307 0.1187216  0.33151492 0.02277732\n",
            " 0.02619224 0.22070363 0.686475   0.06203987 0.15135367 0.25662115\n",
            " 0.20217589 0.05673129 0.4747704  0.71583945 0.06037993 0.03935573\n",
            " 0.5257234  0.5604949  0.03613692 0.1362052  0.24003482 0.00305805\n",
            " 0.01830608 0.77190644 0.09907184 0.05276029 0.03928041 0.2330507\n",
            " 0.7488986  0.15834737 0.02584298 0.03965467]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-586f86c27f7e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Evaluate without hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     results_no_tuning = evaluate_models_with_tuning_adjusted_proportion(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_ohe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-7ed2adb2f8f2>\u001b[0m in \u001b[0;36mevaluate_models_with_tuning_adjusted_proportion\u001b[0;34m(train_ohe, train_label, train_lr, test_ohe_100, test_label_100, test_lr_100, sizes, minority_proportions, random_state, hyperparameter_tuning)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# Train and evaluate logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Logistic regression always outputs two classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             ]\n\u001b[0;32m--> 455\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                  **options)\n\u001b[1;32m    712\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    714\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    715\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[0m\u001b[1;32m    399\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                        isave, dsave, maxls)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.to_csv('/content/drive/MyDrive/Indian_bank_data/traiditional_ML_adjusted_prop_results.csv', index=False)"
      ],
      "metadata": {
        "id": "OyGeOUnuMKZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results_stratified.groupby([\"Model\", \"Tuning\", \"Train Size\", \"Minority Proportion\"]).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F5pohjNJLR8Y",
        "outputId": "33481070-d944-4e65-f3d3-4fcc5f9b1d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                F1    ROCAUC  \\\n",
              "Model              Tuning Train Size Minority Proportion                       \n",
              "DecisionTree       No     8          0.1                  0.148056  0.529089   \n",
              "                          16         0.1                  0.211426  0.543324   \n",
              "                          32         0.1                  0.230769  0.557913   \n",
              "                          64         0.1                  0.230769  0.557913   \n",
              "                          128        0.1                  0.230769  0.557913   \n",
              "                   Yes    8          0.1                  0.000000  0.500000   \n",
              "                          16         0.1                  0.000000  0.489434   \n",
              "                          32         0.1                  0.230769  0.557913   \n",
              "                          64         0.1                  0.230769  0.557913   \n",
              "                          128        0.1                  0.230769  0.557913   \n",
              "LogisticRegression No     8          0.1                  0.253362  0.597215   \n",
              "                          16         0.1                  0.201326  0.529310   \n",
              "                          32         0.1                  0.113592  0.376569   \n",
              "                          64         0.1                  0.115729  0.450575   \n",
              "                          128        0.1                  0.092260  0.462025   \n",
              "                   Yes    8          0.1                  0.253362  0.597215   \n",
              "                          16         0.1                  0.201326  0.529310   \n",
              "                          32         0.1                  0.113592  0.376569   \n",
              "                          64         0.1                  0.115729  0.450575   \n",
              "                          128        0.1                  0.092260  0.462025   \n",
              "RandomForest       No     8          0.1                  0.000000  0.534350   \n",
              "                          16         0.1                  0.000000  0.540009   \n",
              "                          32         0.1                  0.000000  0.561848   \n",
              "                          64         0.1                  0.014286  0.573254   \n",
              "                          128        0.1                  0.021667  0.566180   \n",
              "                   Yes    8          0.1                  0.000000  0.500000   \n",
              "                          16         0.1                  0.000000  0.550884   \n",
              "                          32         0.1                  0.000000  0.556233   \n",
              "                          64         0.1                  0.000000  0.576879   \n",
              "                          128        0.1                  0.042857  0.570203   \n",
              "XGBoost            No     8          0.1                  0.000000  0.500000   \n",
              "                          16         0.1                  0.000000  0.464545   \n",
              "                          32         0.1                  0.041863  0.442971   \n",
              "                          64         0.1                  0.230769  0.574801   \n",
              "                          128        0.1                  0.230769  0.583599   \n",
              "                   Yes    8          0.1                  0.000000  0.500000   \n",
              "                          16         0.1                  0.000000  0.493457   \n",
              "                          32         0.1                  0.023810  0.465606   \n",
              "                          64         0.1                  0.226740  0.522104   \n",
              "                          128        0.1                  0.230769  0.582361   \n",
              "\n",
              "                                                             PRAUC  Iteration  \n",
              "Model              Tuning Train Size Minority Proportion                       \n",
              "DecisionTree       No     8          0.1                  0.144992        5.5  \n",
              "                          16         0.1                  0.148450        5.5  \n",
              "                          32         0.1                  0.153254        5.5  \n",
              "                          64         0.1                  0.153254        5.5  \n",
              "                          128        0.1                  0.153254        5.5  \n",
              "                   Yes    8          0.1                  0.130000        5.5  \n",
              "                          16         0.1                  0.137423        5.5  \n",
              "                          32         0.1                  0.153254        5.5  \n",
              "                          64         0.1                  0.153254        5.5  \n",
              "                          128        0.1                  0.153254        5.5  \n",
              "LogisticRegression No     8          0.1                  0.200022        5.5  \n",
              "                          16         0.1                  0.211544        5.5  \n",
              "                          32         0.1                  0.177702        5.5  \n",
              "                          64         0.1                  0.190337        5.5  \n",
              "                          128        0.1                  0.168424        5.5  \n",
              "                   Yes    8          0.1                  0.200022        5.5  \n",
              "                          16         0.1                  0.211544        5.5  \n",
              "                          32         0.1                  0.177702        5.5  \n",
              "                          64         0.1                  0.190337        5.5  \n",
              "                          128        0.1                  0.168424        5.5  \n",
              "RandomForest       No     8          0.1                  0.179771        5.5  \n",
              "                          16         0.1                  0.174494        5.5  \n",
              "                          32         0.1                  0.208207        5.5  \n",
              "                          64         0.1                  0.216720        5.5  \n",
              "                          128        0.1                  0.205040        5.5  \n",
              "                   Yes    8          0.1                  0.130000        5.5  \n",
              "                          16         0.1                  0.203700        5.5  \n",
              "                          32         0.1                  0.186630        5.5  \n",
              "                          64         0.1                  0.228822        5.5  \n",
              "                          128        0.1                  0.236136        5.5  \n",
              "XGBoost            No     8          0.1                  0.130000        5.5  \n",
              "                          16         0.1                  0.136762        5.5  \n",
              "                          32         0.1                  0.149276        5.5  \n",
              "                          64         0.1                  0.212854        5.5  \n",
              "                          128        0.1                  0.244256        5.5  \n",
              "                   Yes    8          0.1                  0.130000        5.5  \n",
              "                          16         0.1                  0.129427        5.5  \n",
              "                          32         0.1                  0.151868        5.5  \n",
              "                          64         0.1                  0.200759        5.5  \n",
              "                          128        0.1                  0.233023        5.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d720f66e-d6df-4e43-b074-d7a4b9654eeb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>PRAUC</th>\n",
              "      <th>Iteration</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th>Tuning</th>\n",
              "      <th>Train Size</th>\n",
              "      <th>Minority Proportion</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">DecisionTree</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.148056</td>\n",
              "      <td>0.529089</td>\n",
              "      <td>0.144992</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.211426</td>\n",
              "      <td>0.543324</td>\n",
              "      <td>0.148450</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.489434</td>\n",
              "      <td>0.137423</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">LogisticRegression</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.253362</td>\n",
              "      <td>0.597215</td>\n",
              "      <td>0.200022</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.201326</td>\n",
              "      <td>0.529310</td>\n",
              "      <td>0.211544</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.113592</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.177702</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.115729</td>\n",
              "      <td>0.450575</td>\n",
              "      <td>0.190337</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.092260</td>\n",
              "      <td>0.462025</td>\n",
              "      <td>0.168424</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.253362</td>\n",
              "      <td>0.597215</td>\n",
              "      <td>0.200022</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.201326</td>\n",
              "      <td>0.529310</td>\n",
              "      <td>0.211544</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.113592</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.177702</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.115729</td>\n",
              "      <td>0.450575</td>\n",
              "      <td>0.190337</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.092260</td>\n",
              "      <td>0.462025</td>\n",
              "      <td>0.168424</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">RandomForest</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534350</td>\n",
              "      <td>0.179771</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.540009</td>\n",
              "      <td>0.174494</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.561848</td>\n",
              "      <td>0.208207</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.014286</td>\n",
              "      <td>0.573254</td>\n",
              "      <td>0.216720</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.021667</td>\n",
              "      <td>0.566180</td>\n",
              "      <td>0.205040</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.550884</td>\n",
              "      <td>0.203700</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.556233</td>\n",
              "      <td>0.186630</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576879</td>\n",
              "      <td>0.228822</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.042857</td>\n",
              "      <td>0.570203</td>\n",
              "      <td>0.236136</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">XGBoost</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">No</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.464545</td>\n",
              "      <td>0.136762</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.041863</td>\n",
              "      <td>0.442971</td>\n",
              "      <td>0.149276</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.574801</td>\n",
              "      <td>0.212854</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.583599</td>\n",
              "      <td>0.244256</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Yes</th>\n",
              "      <th>8</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.493457</td>\n",
              "      <td>0.129427</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.465606</td>\n",
              "      <td>0.151868</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.226740</td>\n",
              "      <td>0.522104</td>\n",
              "      <td>0.200759</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <th>0.1</th>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.582361</td>\n",
              "      <td>0.233023</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d720f66e-d6df-4e43-b074-d7a4b9654eeb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d720f66e-d6df-4e43-b074-d7a4b9654eeb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d720f66e-d6df-4e43-b074-d7a4b9654eeb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-962e7abc-ebcc-4221-9006-1c7adabc4985\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-962e7abc-ebcc-4221-9006-1c7adabc4985')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-962e7abc-ebcc-4221-9006-1c7adabc4985 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"final_results_stratified\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10202333690945341,\n        \"min\": 0.0,\n        \"max\": 0.2533623111101691,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.01428571428571428,\n          0.04285714285714284,\n          0.1480555103135748\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROCAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05549345849152252,\n        \"min\": 0.3765694076038904,\n        \"max\": 0.5972148541114058,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.4505747126436782,\n          0.5732537577365163,\n          0.4620247568523431\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.033856324702656294,\n        \"min\": 0.12942736024021903,\n        \"max\": 0.24425630856369782,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.19033708770619945,\n          0.21672017906554836,\n          0.16842386593460593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.5,\n        \"max\": 5.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8la1Fd0kmf5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sizes = [8, 16, 32, 64, 128]\n",
        "\n",
        "# Evaluate without hyperparameter tuning\n",
        "results_no_tuning = evaluate_models_with_tuning(\n",
        "    train_ohe, train_label, train_lr, test_ohe_100, test_label_100, test_lr_100, train_sizes, hyperparameter_tuning=False\n",
        ")\n",
        "\n",
        "# Evaluate with hyperparameter tuning\n",
        "results_with_tuning = evaluate_models_with_tuning(\n",
        "    train_ohe, train_label, train_lr, test_ohe_100, test_label_100, test_lr_100, train_sizes, hyperparameter_tuning=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i5un8or85z7",
        "outputId": "97bf65f4-24d5-4a3a-b2c0-ab32364efb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_no_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "isuRDp50907K",
        "outputId": "2079324e-97e9-47ee-dad0-1b263118d1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model  Train Size        F1    ROCAUC     PRAUC\n",
              "0         RandomForest           8  0.000000  0.501326  0.172362\n",
              "1         DecisionTree           8  0.000000  0.500000  0.130000\n",
              "2              XGBoost           8  0.000000  0.500000  0.130000\n",
              "3   LogisticRegression           8  0.065574  0.320955  0.094832\n",
              "4         RandomForest          16  0.000000  0.541556  0.182542\n",
              "5         DecisionTree          16  0.230769  0.557913  0.153254\n",
              "6              XGBoost          16  0.000000  0.496021  0.157298\n",
              "7   LogisticRegression          16  0.080000  0.428824  0.133497\n",
              "8         RandomForest          32  0.000000  0.626437  0.226795\n",
              "9         DecisionTree          32  0.230769  0.557913  0.153254\n",
              "10             XGBoost          32  0.000000  0.337754  0.099600\n",
              "11  LogisticRegression          32  0.160000  0.473475  0.142865\n",
              "12        RandomForest          64  0.000000  0.563660  0.190973\n",
              "13        DecisionTree          64  0.230769  0.557913  0.153254\n",
              "14             XGBoost          64  0.230769  0.553492  0.162580\n",
              "15  LogisticRegression          64  0.000000  0.610522  0.209048\n",
              "16        RandomForest         128  0.000000  0.516799  0.228361\n",
              "17        DecisionTree         128  0.230769  0.557913  0.153254\n",
              "18             XGBoost         128  0.230769  0.567639  0.237623\n",
              "19  LogisticRegression         128  0.133333  0.655615  0.289152"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34d21577-d9d8-41a8-aac8-6142f65e6dd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train Size</th>\n",
              "      <th>F1</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>PRAUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501326</td>\n",
              "      <td>0.172362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>8</td>\n",
              "      <td>0.065574</td>\n",
              "      <td>0.320955</td>\n",
              "      <td>0.094832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541556</td>\n",
              "      <td>0.182542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>16</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.496021</td>\n",
              "      <td>0.157298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>16</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.428824</td>\n",
              "      <td>0.133497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.626437</td>\n",
              "      <td>0.226795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>32</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.337754</td>\n",
              "      <td>0.099600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>32</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.473475</td>\n",
              "      <td>0.142865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.563660</td>\n",
              "      <td>0.190973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>64</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>64</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.553492</td>\n",
              "      <td>0.162580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610522</td>\n",
              "      <td>0.209048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.516799</td>\n",
              "      <td>0.228361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>128</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>128</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.567639</td>\n",
              "      <td>0.237623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>128</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.655615</td>\n",
              "      <td>0.289152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d21577-d9d8-41a8-aac8-6142f65e6dd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34d21577-d9d8-41a8-aac8-6142f65e6dd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34d21577-d9d8-41a8-aac8-6142f65e6dd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-062ba046-eb6b-47da-8fb9-639ff8795682\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-062ba046-eb6b-47da-8fb9-639ff8795682')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-062ba046-eb6b-47da-8fb9-639ff8795682 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9d88ab35-69ee-4ca8-ba33-1d344898170f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_no_tuning')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9d88ab35-69ee-4ca8-ba33-1d344898170f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_no_tuning');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_no_tuning",
              "summary": "{\n  \"name\": \"results_no_tuning\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"DecisionTree\",\n          \"LogisticRegression\",\n          \"RandomForest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44,\n        \"min\": 8,\n        \"max\": 128,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          16,\n          128,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10446419962960085,\n        \"min\": 0.0,\n        \"max\": 0.23076923076923078,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          0.06557377049180328,\n          0.13333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROCAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0841167906247528,\n        \"min\": 0.32095490716180375,\n        \"max\": 0.6556145004420867,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5013262599469497,\n          0.5,\n          0.4960212201591513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04852700926109543,\n        \"min\": 0.09483230503254918,\n        \"max\": 0.28915208801056363,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.17236208236208236,\n          0.13,\n          0.15729769926369885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_with_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "PM0NxjikDl6u",
        "outputId": "1f404d6f-7cd9-4c77-dcbb-9b3ecdd64b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model  Train Size        F1    ROCAUC     PRAUC\n",
              "0         RandomForest           8  0.000000  0.500000  0.130000\n",
              "1         DecisionTree           8  0.000000  0.500000  0.130000\n",
              "2              XGBoost           8  0.000000  0.500000  0.130000\n",
              "3   LogisticRegression           8  0.065574  0.320955  0.094832\n",
              "4         RandomForest          16  0.000000  0.662246  0.283585\n",
              "5         DecisionTree          16  0.000000  0.500000  0.130000\n",
              "6              XGBoost          16  0.000000  0.500000  0.130000\n",
              "7   LogisticRegression          16  0.080000  0.428824  0.133497\n",
              "8         RandomForest          32  0.000000  0.549956  0.247924\n",
              "9         DecisionTree          32  0.230769  0.557913  0.153254\n",
              "10             XGBoost          32  0.000000  0.377542  0.105479\n",
              "11  LogisticRegression          32  0.160000  0.473475  0.142865\n",
              "12        RandomForest          64  0.000000  0.681698  0.249349\n",
              "13        DecisionTree          64  0.230769  0.557913  0.153254\n",
              "14             XGBoost          64  0.230769  0.601238  0.183437\n",
              "15  LogisticRegression          64  0.000000  0.610522  0.209048\n",
              "16        RandomForest         128  0.000000  0.525199  0.200589\n",
              "17        DecisionTree         128  0.230769  0.557913  0.153254\n",
              "18             XGBoost         128  0.230769  0.632184  0.240387\n",
              "19  LogisticRegression         128  0.133333  0.655615  0.289152"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ccc84af-74d0-446a-b541-e9e2c99d1e0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train Size</th>\n",
              "      <th>F1</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>PRAUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>8</td>\n",
              "      <td>0.065574</td>\n",
              "      <td>0.320955</td>\n",
              "      <td>0.094832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.662246</td>\n",
              "      <td>0.283585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>16</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.428824</td>\n",
              "      <td>0.133497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.549956</td>\n",
              "      <td>0.247924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>32</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377542</td>\n",
              "      <td>0.105479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>32</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.473475</td>\n",
              "      <td>0.142865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681698</td>\n",
              "      <td>0.249349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>64</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>64</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.601238</td>\n",
              "      <td>0.183437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610522</td>\n",
              "      <td>0.209048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.525199</td>\n",
              "      <td>0.200589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>128</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.557913</td>\n",
              "      <td>0.153254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>128</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.632184</td>\n",
              "      <td>0.240387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>128</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.655615</td>\n",
              "      <td>0.289152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ccc84af-74d0-446a-b541-e9e2c99d1e0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ccc84af-74d0-446a-b541-e9e2c99d1e0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ccc84af-74d0-446a-b541-e9e2c99d1e0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd1af7c5-b1c5-4f1a-8a16-a891d460b57c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd1af7c5-b1c5-4f1a-8a16-a891d460b57c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd1af7c5-b1c5-4f1a-8a16-a891d460b57c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_221b9abb-dce6-4347-b113-31c3aa377b61\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_with_tuning')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_221b9abb-dce6-4347-b113-31c3aa377b61 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_with_tuning');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_with_tuning",
              "summary": "{\n  \"name\": \"results_with_tuning\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"DecisionTree\",\n          \"LogisticRegression\",\n          \"RandomForest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44,\n        \"min\": 8,\n        \"max\": 128,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          16,\n          128,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10091860699339956,\n        \"min\": 0.0,\n        \"max\": 0.23076923076923078,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          0.06557377049180328,\n          0.13333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROCAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09332448112932872,\n        \"min\": 0.32095490716180375,\n        \"max\": 0.6816976127320955,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.601237842617153,\n          0.5251989389920424,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRAUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05955168678523346,\n        \"min\": 0.09483230503254918,\n        \"max\": 0.28915208801056363,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.1834373757799908,\n          0.20058875424826397,\n          0.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}